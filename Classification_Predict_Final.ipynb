{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Classification Predict Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MfundoMhlanga/classification-predict-streamlit-template/blob/master/Classification_Predict_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBPJ9hI1oPa3"
      },
      "source": [
        "#**<font color='red'>Climate Change Belief Analysis</font>**\n",
        "\n",
        "© Explore Data Science Academy\n",
        "\n",
        "Team 13\n",
        "##**<font color='green'>Introduction: Climate Change Belief</font>**\n",
        "\n",
        "<p align=\"justify\" > Many companies are built around lessening one’s environmental impact or carbon\n",
        "footprint. They offer products and services that are environmentally friendly  and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat.\n",
        "This would add to their market research efforts in gauging how their product/service may be received.\n",
        "\n",
        "##**<font color='cyan'>Problem Statement:</font>**\n",
        "\n",
        "\n",
        "\n",
        "##**<font color='purple'>Task: Classification based on Tweets</font>**\n",
        "<p align=\"justify\" > To create a Machine Learning model that is able to classify whether or not a\n",
        "person believes in climate change, based on their novel tweet data.\n",
        "Hence, providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and\n",
        "geographic categories thus increasing their insights and informing future\n",
        "marketing strategies.\n",
        "\n",
        "<div align=\"center\" style=\"width: 800px; font-size: 100%; text-align: center; margin: 0 auto\">\n",
        "<img src=\"https://raw.githubusercontent.com/MfundoMhlanga/classification-predict-streamlit-template/master/Screenshot%20(480).png\"\n",
        "\n",
        "     alt=\"Climate Change\"\n",
        "     style=\"float: center; padding-bottom=0.5em\"\n",
        "     width=600px/>\n",
        "Climate Change  Photo by <a href=\"https://explore-datascience.net\"> explore-datascience.net </a> \n",
        "</div>\n"
      ],
      "id": "uBPJ9hI1oPa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNg4G34So5B6"
      },
      "source": [
        "# Importing Packages\n",
        "\n",
        "In this section we are importing all the relavant packages which will be used for analysis and modeling."
      ],
      "id": "xNg4G34So5B6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHtZ75xBD7e_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a698b9-066a-4f00-8008-5ae232f02760"
      },
      "source": [
        "!!pip install nlppreprocess"
      ],
      "id": "GHtZ75xBD7e_",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: nlppreprocess in /usr/local/lib/python3.7/dist-packages (1.0.2)']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpR60gDNFQy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b600317a-1880-4881-8864-ef83b89b5e35"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "id": "rpR60gDNFQy1",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl7BaXRYpDN6"
      },
      "source": [
        "# Libraries for data loading, data manipulation and data visulisation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Libraries for data preparation and model building\n",
        "\n",
        "# Import the scaling module\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tabulate import tabulate \n",
        "\n",
        "# Import train/test split module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Modelling \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "# NLP Libraries\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer,SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import pos_tag\n",
        "from nlppreprocess import NLP\n",
        "nlp = NLP()\n",
        "#evaluating the model\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "id": "Gl7BaXRYpDN6",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-whIlITEpsXI"
      },
      "source": [
        "#Loading DataSets\n",
        "\n",
        " Loading the data to be used to build our classification model."
      ],
      "id": "-whIlITEpsXI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-28T08:49:35.311495Z",
          "start_time": "2021-06-28T08:49:35.295494Z"
        },
        "id": "fbbb6c18"
      },
      "source": [
        "# Loading in the datasets\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/MfundoMhlanga/classification-predict-streamlit-template/master/train.csv\")\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/MfundoMhlanga/classification-predict-streamlit-template/master/test_with_no_labels.csv\")\n",
        "\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df1=df.copy()\n",
        "df_test1=df_test.copy()"
      ],
      "id": "fbbb6c18",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a9902d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "a738d8e4-1490-4103-8176-a95ca37089f4"
      },
      "source": [
        "df.head(2)"
      ],
      "id": "0a9902d6",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
              "1          1  It's not like we lack evidence of anthropogeni...   126103"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LuP58PdtKHbI",
        "outputId": "cfb98e81-9375-4283-a90c-2cb69c6b8159"
      },
      "source": [
        "df_test.head(2)"
      ],
      "id": "LuP58PdtKHbI",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Europe will now be looking to China to make su...</td>\n",
              "      <td>169760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message  tweetid\n",
              "0  Europe will now be looking to China to make su...   169760\n",
              "1  Combine this with the polling of staffers re c...    35326"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aheCovyTxDUA"
      },
      "source": [
        "Data Description\n",
        "\n",
        "*   Columns sentiment: Sentiment of tweet \n",
        "*   message: Tweet body\n",
        "*   tweetid: Twitter unique id\n",
        "\n",
        "i.e. We have this features: Sentiments (Target) and Message (feature) including TweetsId\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "aheCovyTxDUA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er_QIMI1vNeH",
        "outputId": "6f57c190-0d3c-43cc-9cde-4c5754a77aba"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "id": "er_QIMI1vNeH",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH5UL_qxxYWV"
      },
      "source": [
        "Class Description \n",
        "\n",
        "\n",
        "*   2 News: the tweet links to factual news about climate change \n",
        "*   1 Pro: the tweet supports the belief of man-made climate change \n",
        "*   0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
        "*   -1 Anti: the tweet does not believe in man-made climate change \n",
        "\n",
        "\n",
        "\n",
        " \n"
      ],
      "id": "eH5UL_qxxYWV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2w7--NjyPE8"
      },
      "source": [
        "<a id=\"three\"></a>\n",
        "# Exploratory Data Analysis\n",
        "\n",
        "\n",
        "<p align=\"justify\" > This section provides an in depth EDA which allowed us to gain deeper insights into the dimensions and features of our data."
      ],
      "id": "O2w7--NjyPE8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwOi1mBtxkHe",
        "outputId": "4d521842-8871-43ab-c754-6b56db4d2a03"
      },
      "source": [
        "#Checking the shape of the train and test set\n",
        "#df=df[:10546]\n",
        "df.shape,df_test.shape"
      ],
      "id": "fwOi1mBtxkHe",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15819, 3), (10546, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48pfhgkCqokV",
        "outputId": "ed65da02-c321-421f-f6d1-daeae527f836"
      },
      "source": [
        "round((df.isnull().sum()/df.shape[0])\n",
        "      *100,2).astype(str)+ ' %'\n"
      ],
      "id": "48pfhgkCqokV",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment    0.0 %\n",
              "message      0.0 %\n",
              "tweetid      0.0 %\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GpulHyrquJB"
      },
      "source": [
        "\n",
        "No Missing Values in our Dataset i.e. we have 0 null values on our data."
      ],
      "id": "8GpulHyrquJB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu4SY0zOqbg3",
        "outputId": "7d996a34-3cf1-4442-c79e-5ce6ea5c1615"
      },
      "source": [
        "df.info()"
      ],
      "id": "Gu4SY0zOqbg3",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15819 entries, 0 to 15818\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sentiment  15819 non-null  int64 \n",
            " 1   message    15819 non-null  object\n",
            " 2   tweetid    15819 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 370.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAJ6PqRYqepD"
      },
      "source": [
        "The data types are object and 2 integers (tweetid and Sentiment) but since Sentiments is suppose to be a category, we will change it to catergory type.\n",
        "\n"
      ],
      "id": "AAJ6PqRYqepD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "BJj3WrQMyvr2",
        "outputId": "503be229-2606-4ab6-914b-bf7dd5403a9a"
      },
      "source": [
        "# Visualizing the distribution of the feature to the target\n",
        "sns.barplot(df['sentiment'].value_counts().index,df['sentiment'].value_counts())"
      ],
      "id": "BJj3WrQMyvr2",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd899666a50>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "pTZ34NBz_8cH",
        "outputId": "a65ca6f8-a3b3-42ec-f9fe-f8ac9ac0bf17"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels = list( {2: \"News\", 1: \"Pro\",  0: \"Neutral\", -1: \"Anti\"}.values())\n",
        "\n",
        "#my_labels = 'Tasks Pending','Tasks Ongoing','Tasks Completed'\n",
        "my_colors = ['lightblue','lightsteelblue','silver', 'red']\n",
        "my_explode = tuple([0.1] * len(labels)) #(0, 0.1, 0)\n",
        "plt.pie(df['sentiment'].value_counts(), labels=labels, autopct='%1.1f%%', startangle=10, shadow = True, colors=my_colors, explode=my_explode)\n",
        " \n",
        "\n",
        "plt.title('Tweets Categories')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "id": "pTZ34NBz_8cH",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IQ22gPx_TRs"
      },
      "source": [
        "# Data cleaning for furthur sentiment analysis\n",
        "\n",
        "def cleaner(line):\n",
        "    '''\n",
        "    For preprocessing the data, we regularize, transform each upper case into lower case, tokenize,\n",
        "    normalize and remove stopwords. Normalization transforms a token to its root word i.e. \n",
        "    These words would be transformed from \"love loving loved\" to \"love love love.\"\n",
        "    \n",
        "    '''\n",
        "\n",
        "    # Removes RT, url and trailing white spaces\n",
        "    line = re.sub(r'^RT ','', re.sub(r'https://t.co/\\w+', '', line).strip()) \n",
        "    emojis = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # removes emoticons,\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    line = emojis.sub(r'', line)\n",
        "\n",
        "    # Removes puctuation\n",
        "    punctuation = re.compile(\"[.;:!\\'’‘“”?,\\\"()\\[\\]]\")\n",
        "    tweet = punctuation.sub(\"\", line.lower()) \n",
        "    # Removes stopwords\n",
        "    nlp_for_stopwords = NLP(replace_words=True, remove_stopwords=True, \n",
        "                            remove_numbers=True, remove_punctuations=False) \n",
        "    tweet = nlp_for_stopwords.process(tweet) # This will remove stops words that are not necessary. The idea is to keep words like [is, not, was]\n",
        "    # https://towardsdatascience.com/why-you-should-avoid-removing-stopwords-aa7a353d2a52\n",
        "\n",
        "    tweet = tweet.split() \n",
        "    pos = pos_tag(tweet)\n",
        "    \n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tweet = ' '.join([lemmatizer.lemmatize(word, po[0].lower()) \n",
        "                      if (po[0].lower() in ['n', 'r', 'v', 'a'] and word[0] != '@') else word for word, po in pos])\n",
        "    return tweet"
      ],
      "id": "3IQ22gPx_TRs",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmNKWglTEnHl",
        "outputId": "9366b6aa-68e6-48c3-e3ba-a07eb295b29e"
      },
      "source": [
        "# Comparison of Tweets before we apply the function cleaner and after\n",
        "tweet = df.iloc[7,1]\n",
        "tweet_clean = cleaner(tweet)\n",
        "print('BEFORE\\n', tweet)\n",
        "print('AFTER\\n', tweet_clean)"
      ],
      "id": "wmNKWglTEnHl",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE\n",
            " RT @makeandmendlife: Six big things we can ALL do today to fight climate change, or how to be a climate activistÃ¢â‚¬Â¦ https://t.co/TYMLu6DbNM hÃ¢â‚¬Â¦\n",
            "AFTER\n",
            " @makeandmendlife six big thing we can today fight climate change how climate activistã¢â‚¬â¦ hã¢â‚¬â¦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "AnFVqILulUkb",
        "outputId": "554ceafe-cb5f-4a9d-8aa7-2e0f39a9879d"
      },
      "source": [
        "df['clean']  = df['message'].apply(cleaner)\n",
        "df.head()"
      ],
      "id": "AnFVqILulUkb",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "      <td>polyscimajor epa chief not think carbon dioxid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "      <td>its not like we lack evidence anthropogenic gl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "      <td>@rawstory researcher say we three year act cli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "      <td>#todayinmaker# wire pivotal year in war climat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "      <td>@soynoviodetodas its and racist sexist climate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                              clean\n",
              "0          1  ...  polyscimajor epa chief not think carbon dioxid...\n",
              "1          1  ...  its not like we lack evidence anthropogenic gl...\n",
              "2          2  ...  @rawstory researcher say we three year act cli...\n",
              "3          1  ...  #todayinmaker# wire pivotal year in war climat...\n",
              "4          1  ...  @soynoviodetodas its and racist sexist climate...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "2Hqefq9xIQkM",
        "outputId": "10e0c4c0-91c6-42eb-ba44-eedc7b4b5d1d"
      },
      "source": [
        "df_test['clean']  = df_test['message'].apply(cleaner)\n",
        "df_test.head()"
      ],
      "id": "2Hqefq9xIQkM",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Europe will now be looking to China to make su...</td>\n",
              "      <td>169760</td>\n",
              "      <td>europe will now look china make sure not alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "      <td>combine with poll staffer re climate change an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The scary, unimpeachable evidence that climate...</td>\n",
              "      <td>224985</td>\n",
              "      <td>scary unimpeachable evidence climate change al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
              "      <td>476263</td>\n",
              "      <td>@karoli @morgfair @osborneink @dailykos putin ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
              "      <td>872928</td>\n",
              "      <td>@fakewillmoore female orgasm cause global warm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message  ...                                              clean\n",
              "0  Europe will now be looking to China to make su...  ...  europe will now look china make sure not alone...\n",
              "1  Combine this with the polling of staffers re c...  ...  combine with poll staffer re climate change an...\n",
              "2  The scary, unimpeachable evidence that climate...  ...  scary unimpeachable evidence climate change al...\n",
              "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...  ...  @karoli @morgfair @osborneink @dailykos putin ...\n",
              "4  RT @FakeWillMoore: 'Female orgasms cause globa...  ...  @fakewillmoore female orgasm cause global warm...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilEIqJecoNIO"
      },
      "source": [
        ""
      ],
      "id": "ilEIqJecoNIO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "1C4vGQ6K_aIt",
        "outputId": "10b45e00-d1f1-40a9-95d3-1bb36ec55d24"
      },
      "source": [
        "df=df.drop('message', axis=1)\n",
        "df_test=df_test.drop('message', axis=1)\n",
        "df_test.head()"
      ],
      "id": "1C4vGQ6K_aIt",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>169760</td>\n",
              "      <td>europe will now look china make sure not alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35326</td>\n",
              "      <td>combine with poll staffer re climate change an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>224985</td>\n",
              "      <td>scary unimpeachable evidence climate change al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>476263</td>\n",
              "      <td>@karoli @morgfair @osborneink @dailykos putin ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872928</td>\n",
              "      <td>@fakewillmoore female orgasm cause global warm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweetid                                              clean\n",
              "0   169760  europe will now look china make sure not alone...\n",
              "1    35326  combine with poll staffer re climate change an...\n",
              "2   224985  scary unimpeachable evidence climate change al...\n",
              "3   476263  @karoli @morgfair @osborneink @dailykos putin ...\n",
              "4   872928  @fakewillmoore female orgasm cause global warm..."
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AYiwV3QdKK2"
      },
      "source": [
        "# Modelling\n",
        "#Splitting the data\n",
        "\n",
        "Split dataset into Dependent and independent variables. We are to split the dataset into dependent (Y) and independent variables (X)."
      ],
      "id": "3AYiwV3QdKK2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a12aacc1"
      },
      "source": [
        "y=df1['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(df1['message'], y, test_size=0.30, stratify=y, random_state=42)"
      ],
      "id": "a12aacc1",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_iahvQXvX5B"
      },
      "source": [
        "# init stemmer\n",
        "porter_stemmer=PorterStemmer()\n",
        "\n",
        "def my_cool_preprocessor(text):\n",
        "    \n",
        "    text=text.lower() \n",
        "    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
        "    text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n",
        "    \n",
        "    # stem words\n",
        "    words=re.split(\"\\\\s+\",text)\n",
        "    stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
        "    return ' '.join(stemmed_words)"
      ],
      "id": "o_iahvQXvX5B",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18abe2bf"
      },
      "source": [
        "#count_vectorizer = CountVectorizer(stop_words = 'english',  max_df = 0.95)\n",
        "count_vectorizer = CountVectorizer(lowercase = True, ngram_range=(1, 2), analyzer='word', max_df = 0.70, preprocessor=my_cool_preprocessor) #char_wb, word\n",
        "count_train = count_vectorizer.fit_transform(X_train.values)\n",
        "count_test = count_vectorizer.transform(X_test.values)\n",
        "count_df_test = count_vectorizer.transform(df_test1['message'].values)"
      ],
      "id": "18abe2bf",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58209445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba501c33-d2ee-45c6-fe35-69b1edb30787"
      },
      "source": [
        "count_vectorizer.get_feature_names()[:10]"
      ],
      "id": "58209445",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '00 19',\n",
              " '00 am',\n",
              " '00 appropri',\n",
              " '000',\n",
              " '000 000',\n",
              " '000 _connector_',\n",
              " '000 doctor',\n",
              " '000 farmer',\n",
              " '000 from']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJtCN27oXnk0"
      },
      "source": [
        "Tfidf Vectorizer"
      ],
      "id": "tJtCN27oXnk0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4eaf286"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.95)\n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
        "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
        "tfidf_df_test = tfidf_vectorizer.transform(df_test['clean'].values)"
      ],
      "id": "a4eaf286",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPZzAsTw1rTi"
      },
      "source": [
        "#Train Model\n",
        "After data preparation, we are now creating and training the model using Scikit-learn. We import the different classification model from skicit-learn, instantiate the model, and fit the model on the training data. We set the random state for reproducible results.\n"
      ],
      "id": "dPZzAsTw1rTi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSmCiNQPcVAL"
      },
      "source": [
        "Naive classifier"
      ],
      "id": "XSmCiNQPcVAL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yeL1aBVvosx",
        "outputId": "2d062a4e-d54b-4076-d239-0f5a4a1cfb82"
      },
      "source": [
        "nb_classifier = MultinomialNB().fit(count_train, y_train)\n",
        "pred = nb_classifier.predict(count_test)\n",
        "metrics.accuracy_score(y_test ,pred)\n",
        "f1_score(y_test, pred, average='macro')\n",
        "print(metrics.accuracy_score(y_test ,pred))\n",
        "print(f1_score(y_test, pred, average=\"macro\"))"
      ],
      "id": "4yeL1aBVvosx",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7050147492625368\n",
            "0.5049834781532239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqDeXJf2JQo"
      },
      "source": [
        "Random Forest"
      ],
      "id": "wGqDeXJf2JQo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85-_bkaw2IRg",
        "outputId": "c81eceb6-13c2-4d0b-eaef-6d8b7e29bbca"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier().fit(count_train, y_train)\n",
        "rfc_pred = rfc.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,rfc_pred))\n",
        "print(f1_score(y_test, rfc_pred, average=\"macro\"))"
      ],
      "id": "85-_bkaw2IRg",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7138643067846607\n",
            "0.5446330494953585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6avNkMlfetZ"
      },
      "source": [
        "Logistic Regression"
      ],
      "id": "S6avNkMlfetZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuGhMIoU39wP",
        "outputId": "4f0ab715-75c1-4b9c-9b55-b25745055a46"
      },
      "source": [
        "lr=LogisticRegression(multi_class='ovr', solver=\"sag\", random_state=100) #multi_class{‘auto’, ‘ovr’, ‘multinomial’}, \n",
        "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
        "\n",
        "lr.fit(count_train, y_train)\n",
        "lr_pred = lr.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,lr_pred))\n",
        "print(f1_score(y_test, lr_pred, average=\"macro\"))"
      ],
      "id": "WuGhMIoU39wP",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7517909818794775\n",
            "0.6550919096119828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N1XerRGBJA6T",
        "outputId": "a3f3625d-4e52-4f60-d9ac-b121aed865fd"
      },
      "source": [
        "# Creating the hyperparameter grid\n",
        "\n",
        "  \n",
        "# Instantiating logistic regression classifier\n",
        "#logreg = LogisticRegression(multi_class='multinomial', solver=\"saga\", random_state=100)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "param_grid = {\n",
        "    'C': [0.001,100] #0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'max_iter': list(range(100,800,100)),\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "  \n",
        "# Instantiating the GridSearchCV object\n",
        "logreg_cv = GridSearchCV(logreg, param_grid, refit = True, verbose = 3, cv = 5).fit(count_train, y_train)\n",
        "  \n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
        "print(\"Best score is {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "\n",
        "log_pred = logreg_cv.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,log_pred))\n",
        "print(f1_score(y_test, log_pred, average=\"macro\"))"
      ],
      "id": "N1XerRGBJA6T",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.540 total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.7s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.2s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.1s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.8s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.9s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.602 total time=   5.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.597 total time=   5.2s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.591 total time=   5.1s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.596 total time=   5.1s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.9s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.602 total time=   1.4s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.606 total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.597 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.595 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.598 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.600 total time=   2.1s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.540 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   5.4s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.1s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.7s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.8s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.7s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.597 total time=   5.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.8s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.8s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.599 total time=   5.0s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.599 total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.604 total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.597 total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.593 total time=   4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.597 total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.600 total time=   4.1s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.540 total time=   7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   8.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   8.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.7s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.8s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.7s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.8s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.591 total time=   5.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.7s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.8s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.603 total time=   5.6s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.598 total time=   5.8s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.592 total time=   5.8s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.597 total time=   5.5s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.599 total time=   5.9s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.540 total time=   0.4s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.540 total time=   8.3s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=   9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=  10.5s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=   0.4s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=   3.1s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.1s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.1s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.8s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.9s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.9s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.7s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.8s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.596 total time=   5.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.9s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.603 total time=   5.8s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.598 total time=   5.8s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.592 total time=   5.7s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.597 total time=   5.7s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.599 total time=   5.8s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.540 total time=   9.1s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=  11.6s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=   0.5s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.597 total time=   8.9s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.591 total time=   8.9s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.6s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.6s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.9s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.9s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.9s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.6s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.7s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.597 total time=   1.2s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.591 total time=   1.2s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.596 total time=   1.1s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.599 total time=   1.2s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.603 total time=   5.4s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.598 total time=   5.3s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.592 total time=   5.6s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.597 total time=   5.3s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.599 total time=   5.4s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.540 total time=   7.9s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=   8.4s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=  10.4s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=   8.9s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=   2.8s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.7s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.6s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.8s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.7s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.9s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.7s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.8s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.597 total time=   1.2s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.591 total time=   1.2s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.599 total time=   1.2s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.603 total time=   5.7s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.598 total time=   5.6s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   5.6s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.597 total time=   5.4s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.599 total time=   5.5s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.540 total time=   8.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   8.8s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   0.4s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   8.3s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.602 total time=   7.9s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.597 total time=   8.8s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.591 total time=   8.6s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.6s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.7s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.7s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.8s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.591 total time=   5.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.9s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.8s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.597 total time=   1.2s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.603 total time=   5.5s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.598 total time=   5.6s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.592 total time=   5.7s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.597 total time=   5.6s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.599 total time=   5.8s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.587 total time=   0.7s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.577 total time=   0.8s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.585 total time=   0.7s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.586 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.584 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.586 total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.584 total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.590 total time=   2.8s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.4s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.8s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.8s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.7s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.7s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.3s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.3s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.1s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.6s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.691 total time=   7.8s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.674 total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.682 total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.696 total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.696 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.691 total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.676 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.684 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.697 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.696 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.690 total time=   2.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.577 total time=   0.6s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.585 total time=   0.6s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.586 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.584 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.585 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.584 total time=   5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.590 total time=   5.3s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.4s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.6s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.5s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.6s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.2s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.6s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.1s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.6s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.3s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.660 total time=   0.4s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.697 total time=   2.1s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.676 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.682 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.696 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.698 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.691 total time=   4.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.591 total time=   0.6s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.577 total time=   0.6s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.585 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.584 total time=   7.2s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.585 total time=   7.6s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.585 total time=   6.7s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.591 total time=   7.1s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.5s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.8s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.6s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.6s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.1s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.5s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.2s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.8s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.2s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.681 total time=   0.5s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.682 total time=   2.2s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.697 total time=   2.3s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.696 total time=   2.2s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.691 total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.674 total time=   6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.683 total time=   6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.697 total time=   6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.696 total time=   5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.691 total time=   5.9s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.587 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.577 total time=   0.8s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.585 total time=   0.7s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.585 total time=   7.3s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   6.3s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.591 total time=   6.7s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.2s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.7s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.6s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.674 total time=   7.8s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.7s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.4s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.5s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.1s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.660 total time=   0.4s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.665 total time=   0.4s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.686 total time=   0.5s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.674 total time=   2.2s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.697 total time=   2.1s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.674 total time=   7.2s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.683 total time=   6.8s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.697 total time=   7.3s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.696 total time=   7.3s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.692 total time=   7.2s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.577 total time=   0.8s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.585 total time=   0.6s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.587 total time=   6.9s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.584 total time=   6.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.585 total time=   7.1s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.584 total time=   6.2s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.591 total time=   6.7s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.2s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.6s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.5s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.6s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.1s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.5s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.7s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.1s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.686 total time=   0.5s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.681 total time=   0.5s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.682 total time=   2.2s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.697 total time=   2.2s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.696 total time=   2.2s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.674 total time=   7.4s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.683 total time=   6.9s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.697 total time=   7.2s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.696 total time=   7.2s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.692 total time=   7.1s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.591 total time=   0.6s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.587 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.577 total time=   0.6s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.588 total time=   0.6s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.585 total time=   0.6s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.584 total time=   6.9s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.585 total time=   7.3s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.584 total time=   6.1s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.591 total time=   6.7s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.3s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.4s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.5s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.3s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.4s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.4s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.3s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.2s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.686 total time=   0.5s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.674 total time=   2.2s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.697 total time=   2.1s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.674 total time=   7.5s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.683 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.697 total time=   7.2s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.696 total time=   7.5s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.692 total time=   7.2s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.591 total time=   0.6s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.577 total time=   0.7s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.588 total time=   0.8s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.585 total time=   0.7s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.584 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.585 total time=   7.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.584 total time=   6.2s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.591 total time=   6.9s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.3s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.6s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.5s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.3s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.9s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.2s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.660 total time=   0.4s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.697 total time=   2.2s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.674 total time=   7.4s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.683 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.697 total time=   7.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.696 total time=   7.4s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.692 total time=   7.4s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.667 total time=   0.8s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.656 total time=   0.9s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.688 total time=   0.9s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.679 total time=   0.9s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.686 total time=   0.9s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.674 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.666 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.690 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.689 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.693 total time=   3.7s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.738 total time=  16.7s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.732 total time=  16.4s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.749 total time=  17.9s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.749 total time=  17.6s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.741 total time=  17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.738 total time=  17.2s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.732 total time=  17.5s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-5071e5fc010e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Instantiating the GridSearchCV object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlogreg_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Print the tuned parameters and score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             )\n\u001b[1;32m    814\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"newton-cg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmatmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    568\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    569\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;31m####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvecs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[0;32m--> 487\u001b[0;31m            other.ravel(), result.ravel())\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX8_ZNC6fcrO",
        "outputId": "b5b715fd-1059-4efc-e0b2-fa1acb6e1c4f"
      },
      "source": [
        "lr=LogisticRegression(multi_class='multinomial', solver=\"saga\", random_state=100) #multi_class{‘auto’, ‘ovr’, ‘multinomial’}, \n",
        "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
        "\n",
        "lr.fit(count_train, y_train)\n",
        "lr_pred = lr.predict(count_test)\n",
        "metrics.accuracy_score(y_test ,lr_pred)\n"
      ],
      "id": "gX8_ZNC6fcrO",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7498946481247366"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oixccybdfcun",
        "outputId": "80371af5-2560-4da7-b74f-ae8e7360da29"
      },
      "source": [
        "f1_score(y_test, lr_pred, average=\"macro\")"
      ],
      "id": "oixccybdfcun",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6557587686600752"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8YPR6Nppbg2"
      },
      "source": [
        "Ridge Classifier"
      ],
      "id": "i8YPR6Nppbg2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMAesUV2pZC4",
        "outputId": "219b859e-151d-4cdf-d94e-44e84d68f5db"
      },
      "source": [
        "rc = RidgeClassifier()\n",
        "\n",
        "rrc=RidgeClassifier(alpha=1.0, solver='auto',tol=0.001).fit(count_train, y_train) #(alpha=1.0, solver='auto',tol=0.001).fit(count_train, y_train)\n",
        "#{‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’, ‘lbfgs’}\n",
        "\n",
        "rcc_pred = rrc.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,rcc_pred))\n",
        "print(f1_score(y_test, rcc_pred, average=\"macro\"))"
      ],
      "id": "oMAesUV2pZC4",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7458912768647282\n",
            "0.6596918744157119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdOR0HOv0foX",
        "outputId": "c369e091-6e3b-41d4-9c42-e5df29a82e5b"
      },
      "source": [
        "\n",
        "rrc=RidgeClassifier(alpha=10, solver='cholesky',tol=0.08, fit_intercept=False).fit(count_train, y_train) #(alpha=1.0, solver='auto',tol=0.001).fit(count_train, y_train)\n",
        "#{‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’, ‘lbfgs’}\n",
        "\n",
        "rcc_pred = rrc.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,rcc_pred))\n",
        "print(f1_score(y_test, rcc_pred, average=\"macro\"))"
      ],
      "id": "bdOR0HOv0foX",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7511588706278972\n",
            "0.6528527500795417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h02o7Dv0LGx",
        "outputId": "b5106d37-811e-4495-9442-4d3a724e2335"
      },
      "source": [
        "model = RidgeClassifier()\n",
        "alpha = [0.1, 0.2, 0.9, 1.0]\n",
        "# define grid search\n",
        "grid = dict(alpha=alpha)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "ridge = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0).fit(count_train, y_train)\n",
        "ridge_pred = ridge.predict(count_test)\n",
        "metrics.accuracy_score(y_test ,ridge_pred)"
      ],
      "id": "7h02o7Dv0LGx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7458912768647282"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI3gRN3epZFo",
        "outputId": "f4f359fa-09dc-4a0a-8430-240c579cb640"
      },
      "source": [
        "f1_score(y_test, lr_pred, average=\"macro\")"
      ],
      "id": "VI3gRN3epZFo",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6550919096119828"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_44kZybQqIqL"
      },
      "source": [
        "MLP Classifier"
      ],
      "id": "_44kZybQqIqL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20NeKMP1qI5X",
        "outputId": "6cd558cd-ad0c-4223-ff65-bfc7d40ff2aa"
      },
      "source": [
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,50,30),\n",
        "                        max_iter = 10,activation = 'tanh',\n",
        "                        solver = 'adam').fit(count_train, y_train)\n",
        "\n",
        "mlp_pred = mlp_clf.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,mlp_pred))\n",
        "print(f1_score(y_test, mlp_pred, average=\"macro\"))\n"
      ],
      "id": "20NeKMP1qI5X",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7488411293721028\n",
            "0.6627649692352936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoLWq-O0qJGo"
      },
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30)],\n",
        "    'max_iter': [50, 100, 150],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "grid = GridSearchCV(mlp_clf, param_grid, n_jobs= -1, cv=5)\n",
        "grid.fit(count_train, y_train)\n",
        "\n",
        "print(grid.best_params_) \n",
        "\n",
        "\n",
        "grid_predictions = grid.predict(count_test)"
      ],
      "id": "BoLWq-O0qJGo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKjbLLd1F3Wq"
      },
      "source": [
        "SVC"
      ],
      "id": "iKjbLLd1F3Wq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0d84867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471216fd-6bad-478e-a324-fd211b7e017e"
      },
      "source": [
        "#svc = SVC(kernel='linear', gamma='auto', coef0=0.0000001, tol=0.0000002)   #,random_state=78)#{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
        "svc= SVC(kernel='rbf', C=10.0, random_state=1).fit(count_train, y_train)\n",
        "sv_pred = svc.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,sv_pred))\n",
        "print(f1_score(y_test, sv_pred, average=\"macro\"))"
      ],
      "id": "b0d84867",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7475769068689423\n",
            "0.6425191948546116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXbVfDwwrwaf"
      },
      "source": [
        "Linear SVC"
      ],
      "id": "TXbVfDwwrwaf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V07MFIwZEN-V",
        "outputId": "a2cef75b-716c-49de-8ca5-a95ca1585fe7"
      },
      "source": [
        "svc = svm.LinearSVC().fit(count_train, y_train)\n",
        "sv_pred = svc.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,sv_pred))\n",
        "print(f1_score(y_test, sv_pred, average=\"macro\"))"
      ],
      "id": "V07MFIwZEN-V",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7511588706278972\n",
            "0.6638012039186718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83741bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c07ec82-4b67-4790-dd0d-a2fee7e376ff"
      },
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_test, y_pred=sv_pred, labels=[-1, 0, 1, 2])\n",
        "conf_matrix"
      ],
      "id": "83741bdd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  64,   22,  173,   19],\n",
              "       [   3,  158,  242,   22],\n",
              "       [   3,   52, 1555,  145],\n",
              "       [   3,    8,  160,  535]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17d7c12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5ee97c76-2ef6-489d-9b7f-4cd60e4cd5b1"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.seismic, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "id": "17d7c12e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke9S3DGFYxpe"
      },
      "source": [
        "#Evaluating Models i.e Making Predictions on the Test Set:"
      ],
      "id": "Ke9S3DGFYxpe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFFo7TGrYs1-"
      },
      "source": [
        "# evaluate one or more ML models\n",
        "\n",
        "# Make training set predictions for each model\n",
        "pred_train_nb = nb_classifier.predict(count_train)  \n",
        "pred_test_nb = nb_classifier.predict(count_test) \n",
        "\n",
        "\n",
        "pred_train_rfc = rfc.predict(count_train) \n",
        "pred_test_rfc= rfc.predict(count_test)\n",
        "\n",
        "pred_train_lr = lr.predict(count_train) \n",
        "pred_test_lr= lr.predict(count_test)\n",
        "\n",
        "\n",
        "pred_train_rrc = rrc.predict(count_train) \n",
        "pred_test_rrc= rrc.predict(count_test)\n",
        "\n",
        "pred_train_mlp= mlp_clf.predict(count_train) \n",
        "pred_test_mlp= mlp_clf.predict(count_test)\n",
        "\n",
        "pred_train_svc= svc.predict(count_train) \n",
        "pred_test_svc= svc.predict(count_test)\n",
        "\n"
      ],
      "id": "mFFo7TGrYs1-",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE-4gIKBrLFA"
      },
      "source": [
        "# Comparing Model Performance: \n",
        "\n",
        "The Model is tested using and Error metrics which  enables us to track the efficiency and accuracy. The metrics we are using is called the F1_score. "
      ],
      "id": "YE-4gIKBrLFA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Je3Zmo4r9Dt"
      },
      "source": [
        "Formula\n",
        "\n"
      ],
      "id": "6Je3Zmo4r9Dt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK39-qybrLUw"
      },
      "source": [
        "### Model Performance Accuracy"
      ],
      "id": "wK39-qybrLUw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcQKPQBJZ8ru"
      },
      "source": [
        "# Compare model performance\n",
        "\n",
        "# Dictionary of results\n",
        "results_dict = {'Training accuracy_score':\n",
        "                    {\n",
        "                        \"Naive B\": metrics.accuracy_score(y_train ,pred_train_nb), \n",
        "                        \"FOREST\": metrics.accuracy_score(y_train ,pred_train_rfc),\n",
        "                        \"Logistic\":metrics.accuracy_score(y_train ,pred_train_lr),\n",
        "                        \"Ridge Classifier\": metrics.accuracy_score(y_train ,pred_train_rrc),\n",
        "                        \"MLP Classifier\": metrics.accuracy_score(y_train ,pred_train_mlp),\n",
        "                        \"Support Vector Classifier\": metrics.accuracy_score(y_train ,pred_train_svc)\n",
        "                      \n",
        "                     \n",
        "                     \n",
        "                    },\n",
        "                    'Test accuracy_score':\n",
        "                    {\n",
        "                        \"Naive B\": metrics.accuracy_score(y_test ,pred_test_nb),\n",
        "                        \"FOREST\": metrics.accuracy_score(y_test ,pred_test_rfc),\n",
        "                        \"Logistic\": metrics.accuracy_score(y_test ,pred_test_lr),\n",
        "                        \"Ridge Classifier\": metrics.accuracy_score(y_test ,pred_test_rrc),\n",
        "                        \"MLP Classifier\": metrics.accuracy_score(y_test,pred_test_mlp),\n",
        "                        \"Support Vector Classifier\": metrics.accuracy_score(y_test ,pred_test_svc)\n",
        "                    }\n",
        "                }\n"
      ],
      "id": "EcQKPQBJZ8ru",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNEiWqO_rrSr"
      },
      "source": [
        "### Model Performance F1_score"
      ],
      "id": "eNEiWqO_rrSr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUwY1CJ6onga"
      },
      "source": [
        "# Dictionary of results\n",
        "results_dict_scores = {'F1_score':\n",
        "                    {\n",
        "                        \"Naive B\": f1_score(y_test, pred_test_nb, average=\"macro\"), \n",
        "                        \"FOREST\": f1_score(y_test, pred_test_rfc, average=\"macro\"),\n",
        "                        \"Logistic\":f1_score(y_test, pred_test_lr, average=\"macro\"),\n",
        "                        \"Ridge Classifier\": f1_score(y_test, pred_test_rrc, average=\"macro\"),\n",
        "                        \"MLP Classifier\": f1_score(y_test, pred_test_mlp, average=\"macro\"),\n",
        "                        \"Support Vector Classifier\": f1_score(y_test, pred_test_svc, average=\"macro\")\n",
        "\n",
        "                    }\n",
        "                  \n",
        "                }"
      ],
      "id": "gUwY1CJ6onga",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q69DTvTJrZcD"
      },
      "source": [
        "# Results of all the models\n",
        "The results of the models are summarized and shown with regards to the Training and Testing RMSE."
      ],
      "id": "Q69DTvTJrZcD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjpliRFbseqV"
      },
      "source": [
        "### Results Based on Accuracy"
      ],
      "id": "vjpliRFbseqV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1V_D7XImRY1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "d93970ea-d82d-4549-cd3c-f96f7c2cea4e"
      },
      "source": [
        "# Create dataframe from the dictionary of all the accuracy score results\n",
        "results_df = pd.DataFrame(data=results_dict)\n",
        "results_df"
      ],
      "id": "O1V_D7XImRY1",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training accuracy_score</th>\n",
              "      <th>Test accuracy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive B</th>\n",
              "      <td>0.940034</td>\n",
              "      <td>0.705015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOREST</th>\n",
              "      <td>0.999910</td>\n",
              "      <td>0.713864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic</th>\n",
              "      <td>0.999729</td>\n",
              "      <td>0.749895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge Classifier</th>\n",
              "      <td>0.998194</td>\n",
              "      <td>0.751159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP Classifier</th>\n",
              "      <td>0.999910</td>\n",
              "      <td>0.748841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Classifier</th>\n",
              "      <td>0.999910</td>\n",
              "      <td>0.751159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Training accuracy_score  Test accuracy_score\n",
              "Naive B                                   0.940034             0.705015\n",
              "FOREST                                    0.999910             0.713864\n",
              "Logistic                                  0.999729             0.749895\n",
              "Ridge Classifier                          0.998194             0.751159\n",
              "MLP Classifier                            0.999910             0.748841\n",
              "Support Vector Classifier                 0.999910             0.751159"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yCTaRhmrb1g"
      },
      "source": [
        "### Results Based on F1_score"
      ],
      "id": "6yCTaRhmrb1g"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKvN8JT0rBVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "109dc8c7-7394-4fc4-e5ab-53233f43e879"
      },
      "source": [
        "results_f1score = pd.DataFrame(data=results_dict_scores)\n",
        "results_f1score"
      ],
      "id": "BKvN8JT0rBVc",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FOREST</th>\n",
              "      <td>0.544633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic</th>\n",
              "      <td>0.655759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP Classifier</th>\n",
              "      <td>0.662765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive B</th>\n",
              "      <td>0.504983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge Classifier</th>\n",
              "      <td>0.652853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Classifier</th>\n",
              "      <td>0.663801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           F1_score\n",
              "FOREST                     0.544633\n",
              "Logistic                   0.655759\n",
              "MLP Classifier             0.662765\n",
              "Naive B                    0.504983\n",
              "Ridge Classifier           0.652853\n",
              "Support Vector Classifier  0.663801"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dln8kfsfHFH"
      },
      "source": [
        "###Models Consolidated"
      ],
      "id": "-Dln8kfsfHFH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27IshfJQeKg4",
        "outputId": "858305b9-de2e-46bd-a275-e5336d1e2784"
      },
      "source": [
        "# Creating a list of all the models to train\n",
        "Classifiers = [MultinomialNB(),RandomForestClassifier(), LogisticRegression(multi_class='ovr', solver=\"sag\", random_state=100), RidgeClassifier(alpha=1.0, solver='auto',tol=0.001), MLPClassifier(hidden_layer_sizes=(100,50,30),\n",
        "                        max_iter = 10,activation = 'tanh',\n",
        "                        solver = 'adam'), SVC(kernel = 'linear'), SVC(kernel = 'rbf'), DecisionTreeClassifier()]\n",
        "\n",
        "\n",
        "for n in range(0, len(Classifiers)):\n",
        "    text_clf = Pipeline([('clf', Classifiers[n])])\n",
        "    text_clf.fit(count_train, y_train)  \n",
        "    predictions = text_clf.predict(count_test)\n",
        "    \n",
        "    print(Classifiers[n])\n",
        "    print(metrics.confusion_matrix(y_test,predictions))\n",
        "    print(metrics.classification_report(y_test,predictions))\n",
        "    print('F1_score: ',metrics.f1_score(y_test,predictions, average = 'macro'))\n",
        "    print('New Model\\n')"
      ],
      "id": "27IshfJQeKg4",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n",
            "[[  53    2  323   11]\n",
            " [   2  102  565   37]\n",
            " [   0    4 2445  110]\n",
            " [   2    0  344  746]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.93      0.14      0.24       389\n",
            "           0       0.94      0.14      0.25       706\n",
            "           1       0.66      0.96      0.78      2559\n",
            "           2       0.83      0.68      0.75      1092\n",
            "\n",
            "    accuracy                           0.71      4746\n",
            "   macro avg       0.84      0.48      0.50      4746\n",
            "weighted avg       0.77      0.71      0.65      4746\n",
            "\n",
            "F1_score:  0.5049834781532239\n",
            "New Model\n",
            "\n",
            "RandomForestClassifier()\n",
            "[[  62   30  283   14]\n",
            " [   1  185  478   42]\n",
            " [   2   31 2390  136]\n",
            " [   2    7  330  753]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.93      0.16      0.27       389\n",
            "           0       0.73      0.26      0.39       706\n",
            "           1       0.69      0.93      0.79      2559\n",
            "           2       0.80      0.69      0.74      1092\n",
            "\n",
            "    accuracy                           0.71      4746\n",
            "   macro avg       0.79      0.51      0.55      4746\n",
            "weighted avg       0.74      0.71      0.68      4746\n",
            "\n",
            "F1_score:  0.5471154117940583\n",
            "New Model\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(multi_class='ovr', random_state=100, solver='sag')\n",
            "[[ 152   49  169   19]\n",
            " [  30  301  319   56]\n",
            " [  21  102 2244  192]\n",
            " [   6   14  201  871]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.73      0.39      0.51       389\n",
            "           0       0.65      0.43      0.51       706\n",
            "           1       0.77      0.88      0.82      2559\n",
            "           2       0.77      0.80      0.78      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.73      0.62      0.66      4746\n",
            "weighted avg       0.74      0.75      0.74      4746\n",
            "\n",
            "F1_score:  0.6550919096119828\n",
            "New Model\n",
            "\n",
            "RidgeClassifier()\n",
            "[[ 159   63  148   19]\n",
            " [  24  339  291   52]\n",
            " [  23  127 2194  215]\n",
            " [   6   33  205  848]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.75      0.41      0.53       389\n",
            "           0       0.60      0.48      0.53       706\n",
            "           1       0.77      0.86      0.81      2559\n",
            "           2       0.75      0.78      0.76      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.72      0.63      0.66      4746\n",
            "weighted avg       0.74      0.75      0.74      4746\n",
            "\n",
            "F1_score:  0.6596918744157119\n",
            "New Model\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50, 30), max_iter=10)\n",
            "[[ 160   68  144   17]\n",
            " [  23  337  295   51]\n",
            " [  20  159 2211  169]\n",
            " [   6   24  210  852]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.77      0.41      0.54       389\n",
            "           0       0.57      0.48      0.52       706\n",
            "           1       0.77      0.86      0.82      2559\n",
            "           2       0.78      0.78      0.78      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.72      0.63      0.66      4746\n",
            "weighted avg       0.74      0.75      0.74      4746\n",
            "\n",
            "F1_score:  0.6633233226003652\n",
            "New Model\n",
            "\n",
            "SVC(kernel='linear')\n",
            "[[ 171   63  141   14]\n",
            " [  34  356  281   35]\n",
            " [  40  153 2181  185]\n",
            " [   5   31  187  869]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.68      0.44      0.54       389\n",
            "           0       0.59      0.50      0.54       706\n",
            "           1       0.78      0.85      0.82      2559\n",
            "           2       0.79      0.80      0.79      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.71      0.65      0.67      4746\n",
            "weighted avg       0.75      0.75      0.75      4746\n",
            "\n",
            "F1_score:  0.671604250620598\n",
            "New Model\n",
            "\n",
            "SVC()\n",
            "[[  74   50  236   29]\n",
            " [   9  251  358   88]\n",
            " [   5   64 2217  273]\n",
            " [   1   11  175  905]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.83      0.19      0.31       389\n",
            "           0       0.67      0.36      0.46       706\n",
            "           1       0.74      0.87      0.80      2559\n",
            "           2       0.70      0.83      0.76      1092\n",
            "\n",
            "    accuracy                           0.73      4746\n",
            "   macro avg       0.74      0.56      0.58      4746\n",
            "weighted avg       0.73      0.73      0.70      4746\n",
            "\n",
            "F1_score:  0.5828730918621633\n",
            "New Model\n",
            "\n",
            "KNeighborsClassifier()\n",
            "[[  44  285   58    2]\n",
            " [   6  601   91    8]\n",
            " [  38 1469  995   57]\n",
            " [  11  474  348  259]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.11      0.18       389\n",
            "           0       0.21      0.85      0.34       706\n",
            "           1       0.67      0.39      0.49      2559\n",
            "           2       0.79      0.24      0.37      1092\n",
            "\n",
            "    accuracy                           0.40      4746\n",
            "   macro avg       0.53      0.40      0.34      4746\n",
            "weighted avg       0.61      0.40      0.41      4746\n",
            "\n",
            "F1_score:  0.3442240332681083\n",
            "New Model\n",
            "\n",
            "DecisionTreeClassifier()\n",
            "[[ 107   66  190   26]\n",
            " [  29  249  356   72]\n",
            " [  76  191 2033  259]\n",
            " [  19   37  284  752]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.46      0.28      0.35       389\n",
            "           0       0.46      0.35      0.40       706\n",
            "           1       0.71      0.79      0.75      2559\n",
            "           2       0.68      0.69      0.68      1092\n",
            "\n",
            "    accuracy                           0.66      4746\n",
            "   macro avg       0.58      0.53      0.54      4746\n",
            "weighted avg       0.65      0.66      0.65      4746\n",
            "\n",
            "F1_score:  0.5442784524065772\n",
            "New Model\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1SPa163BWOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "533a4ed5-2855-4480-eee2-b1c0fa065dc2"
      },
      "source": [
        "#pred = svc.predict(count_df_test)\n",
        "pred = rrc.predict(count_df_test)\n",
        "sub = pd.DataFrame({\"tweetid\":df_test['tweetid'], 'sentiment': pred})\n",
        "sub = sub.set_index('tweetid')\n",
        "sub.to_csv('submission.csv',index=True)\n",
        "sub.head()"
      ],
      "id": "E1SPa163BWOH",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweetid</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169760</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35326</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224985</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476263</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872928</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "tweetid           \n",
              "169760           2\n",
              "35326            1\n",
              "224985           1\n",
              "476263           1\n",
              "872928           0"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBnCEhBoc-C4"
      },
      "source": [
        "##Training and Testing Our data on balanced Dataset"
      ],
      "id": "PBnCEhBoc-C4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_adQ7OYL7Dh"
      },
      "source": [
        "###Class Imbalance Data "
      ],
      "id": "5_adQ7OYL7Dh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWUXdrcidT7",
        "outputId": "2a7f4092-6f62-422c-8c61-b4702b71600f"
      },
      "source": [
        "data = df.copy()\n",
        "data['sentiment'].value_counts()"
      ],
      "id": "6xWUXdrcidT7",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVA2bltJidWd",
        "outputId": "682216a6-6530-47ca-dde3-6d7855fd7a56"
      },
      "source": [
        "# There are more instances of class 1 than class 2, class 0 and Class -1 in the data frame df.  \n",
        "\n",
        "# Separate the classes\n",
        "Cat_News = data[data['sentiment']==2]\n",
        "cat_Pro = data[data['sentiment']==1]\n",
        "cat_Neutral = data[data['sentiment']==0]\n",
        "cat_Anti= data[data['sentiment']==-1]\n",
        "\n",
        "# Upsample minority class to match the Majority Class\n",
        "Cat_News = resample(Cat_News,\n",
        "                             replace=True,  # sample with replacement\n",
        "                             n_samples=8530,  # to match majority class\n",
        "                             random_state=300)  # reproducible results\n",
        "cat_Neutral = resample(cat_Neutral,\n",
        "                             replace=True,  # sample with replacement\n",
        "                             n_samples=8530,  # to match majority class\n",
        "                             random_state=300)  # reproducible results\n",
        "cat_Anti = resample(cat_Anti,\n",
        "                             replace=True,  # sample with replacement\n",
        "                             n_samples=8530,  # to match majority class\n",
        "                             random_state=300)  # reproducible results\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "# Display new class counts\n",
        "\n",
        "Balanced = pd.concat([cat_Pro, Cat_News, cat_Neutral,cat_Anti])\n",
        "Balanced['sentiment'].value_counts()"
      ],
      "id": "rVA2bltJidWd",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    8530\n",
              " 2    8530\n",
              " 1    8530\n",
              " 0    8530\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTxOPjzXB4sd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "effb6e0c-d17b-4aef-8f95-b3562b941c81"
      },
      "source": [
        "# Checking if data has been well-balanced\n",
        "sns.countplot(x = Balanced['sentiment'], data = data, palette='tab10')\n",
        "plt.title('Balanced Data')\n",
        "plt.show()"
      ],
      "id": "vTxOPjzXB4sd",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCd79CDtBWRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511038da-96b3-435f-f9db-061c154673ae"
      },
      "source": [
        "#Working with balanced data\n",
        "\n",
        "# Defining the features as well as the label\n",
        "X_new= Balanced['clean']\n",
        "#X_new = X_new.apply(cleaner)\n",
        "X_new=Balanced['clean']\n",
        "y_new = Balanced['sentiment']\n",
        "\n",
        "#Train and Test Split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_new, y_new, test_size=0.40, stratify=y_new,random_state=42)\n",
        "\n",
        "count_vectorizer = CountVectorizer(lowercase = True, ngram_range=(1, 2), analyzer='word', max_df = 0.70, preprocessor=my_cool_preprocessor)#(lowercase = True, ngram_range=(1, 2), analyzer='word')\n",
        "count_train1 = count_vectorizer.fit_transform(X_train1.values)\n",
        "count_test1 = count_vectorizer.transform(X_test1.values)\n",
        "count_df_test1 = count_vectorizer.transform(df_test['clean'].values)\n",
        "\n",
        "\n",
        "for n in range(0, len(Classifiers)):\n",
        "    text_clf = Pipeline([('clf', Classifiers[n])])\n",
        "    text_clf.fit(count_train1, y_train1)  \n",
        "    predictions = text_clf.predict(count_test1)\n",
        "    \n",
        "    \n",
        "    print(Classifiers[n])\n",
        "    print(metrics.confusion_matrix(y_test1,predictions))\n",
        "    print(metrics.classification_report(y_test1,predictions))\n",
        "    print('F1_score: ',round(metrics.f1_score(y_test1,predictions, average = 'macro'),3))\n",
        "    print('-------------------------------------------------------')"
      ],
      "id": "FCd79CDtBWRO",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n",
            "[[3347   24   18   23]\n",
            " [ 145 3068  122   77]\n",
            " [ 253  309 2430  420]\n",
            " [  51   34  122 3205]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.88      0.98      0.93      3412\n",
            "           0       0.89      0.90      0.90      3412\n",
            "           1       0.90      0.71      0.80      3412\n",
            "           2       0.86      0.94      0.90      3412\n",
            "\n",
            "    accuracy                           0.88     13648\n",
            "   macro avg       0.88      0.88      0.88     13648\n",
            "weighted avg       0.88      0.88      0.88     13648\n",
            "\n",
            "F1_score:  0.88\n",
            "-------------------------------------------------------\n",
            "RandomForestClassifier()\n",
            "[[3357   27   28    0]\n",
            " [  26 3263  106   17]\n",
            " [  75  361 2561  415]\n",
            " [  18   66  147 3181]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.98      0.97      3412\n",
            "           0       0.88      0.96      0.92      3412\n",
            "           1       0.90      0.75      0.82      3412\n",
            "           2       0.88      0.93      0.91      3412\n",
            "\n",
            "    accuracy                           0.91     13648\n",
            "   macro avg       0.91      0.91      0.90     13648\n",
            "weighted avg       0.91      0.91      0.90     13648\n",
            "\n",
            "F1_score:  0.904\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(multi_class='ovr', random_state=100, solver='sag')\n",
            "[[3368   33   11    0]\n",
            " [  31 3267   88   26]\n",
            " [  93  321 2642  356]\n",
            " [  17   51  111 3233]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.99      0.97      3412\n",
            "           0       0.89      0.96      0.92      3412\n",
            "           1       0.93      0.77      0.84      3412\n",
            "           2       0.89      0.95      0.92      3412\n",
            "\n",
            "    accuracy                           0.92     13648\n",
            "   macro avg       0.92      0.92      0.91     13648\n",
            "weighted avg       0.92      0.92      0.91     13648\n",
            "\n",
            "F1_score:  0.915\n",
            "-------------------------------------------------------\n",
            "RidgeClassifier()\n",
            "[[3368   29   12    3]\n",
            " [  30 3257  102   23]\n",
            " [  73  303 2677  359]\n",
            " [  13   59  142 3198]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.99      0.98      3412\n",
            "           0       0.89      0.95      0.92      3412\n",
            "           1       0.91      0.78      0.84      3412\n",
            "           2       0.89      0.94      0.91      3412\n",
            "\n",
            "    accuracy                           0.92     13648\n",
            "   macro avg       0.92      0.92      0.91     13648\n",
            "weighted avg       0.92      0.92      0.91     13648\n",
            "\n",
            "F1_score:  0.914\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50, 30), max_iter=10)\n",
            "[[3371   29   12    0]\n",
            " [  39 3232  129   12]\n",
            " [  78  243 2840  251]\n",
            " [  23   54  166 3169]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.99      0.97      3412\n",
            "           0       0.91      0.95      0.93      3412\n",
            "           1       0.90      0.83      0.87      3412\n",
            "           2       0.92      0.93      0.93      3412\n",
            "\n",
            "    accuracy                           0.92     13648\n",
            "   macro avg       0.92      0.92      0.92     13648\n",
            "weighted avg       0.92      0.92      0.92     13648\n",
            "\n",
            "F1_score:  0.923\n",
            "-------------------------------------------------------\n",
            "SVC(kernel='linear')\n",
            "[[3361   34   17    0]\n",
            " [  30 3269  100   13]\n",
            " [  85  355 2673  299]\n",
            " [  12   79  139 3182]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.99      0.97      3412\n",
            "           0       0.87      0.96      0.91      3412\n",
            "           1       0.91      0.78      0.84      3412\n",
            "           2       0.91      0.93      0.92      3412\n",
            "\n",
            "    accuracy                           0.91     13648\n",
            "   macro avg       0.92      0.91      0.91     13648\n",
            "weighted avg       0.92      0.91      0.91     13648\n",
            "\n",
            "F1_score:  0.913\n",
            "-------------------------------------------------------\n",
            "SVC()\n",
            "[[3329   56   20    7]\n",
            " [  25 3222  107   58]\n",
            " [  64  383 2350  615]\n",
            " [   9   60   90 3253]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.98      0.97      3412\n",
            "           0       0.87      0.94      0.90      3412\n",
            "           1       0.92      0.69      0.79      3412\n",
            "           2       0.83      0.95      0.89      3412\n",
            "\n",
            "    accuracy                           0.89     13648\n",
            "   macro avg       0.89      0.89      0.89     13648\n",
            "weighted avg       0.89      0.89      0.89     13648\n",
            "\n",
            "F1_score:  0.887\n",
            "-------------------------------------------------------\n",
            "KNeighborsClassifier()\n",
            "[[3082  326    0    4]\n",
            " [ 182 3201    5   24]\n",
            " [ 374 2328  620   90]\n",
            " [  97 1643   26 1646]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.83      0.90      0.86      3412\n",
            "           0       0.43      0.94      0.59      3412\n",
            "           1       0.95      0.18      0.31      3412\n",
            "           2       0.93      0.48      0.64      3412\n",
            "\n",
            "    accuracy                           0.63     13648\n",
            "   macro avg       0.78      0.63      0.60     13648\n",
            "weighted avg       0.78      0.63      0.60     13648\n",
            "\n",
            "F1_score:  0.598\n",
            "-------------------------------------------------------\n",
            "DecisionTreeClassifier()\n",
            "[[3366   28   16    2]\n",
            " [  51 3237   98   26]\n",
            " [ 230  511 2244  427]\n",
            " [  28  113  158 3113]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.92      0.99      0.95      3412\n",
            "           0       0.83      0.95      0.89      3412\n",
            "           1       0.89      0.66      0.76      3412\n",
            "           2       0.87      0.91      0.89      3412\n",
            "\n",
            "    accuracy                           0.88     13648\n",
            "   macro avg       0.88      0.88      0.87     13648\n",
            "weighted avg       0.88      0.88      0.87     13648\n",
            "\n",
            "F1_score:  0.871\n",
            "-------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6TV-1CHey4L"
      },
      "source": [
        "#Final Model Selected From Balanced Data Set"
      ],
      "id": "E6TV-1CHey4L"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQtxBCrue8Xf"
      },
      "source": [
        "Logistic Regression"
      ],
      "id": "eQtxBCrue8Xf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYOX61K1DxVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0630cd4-2f6a-46ba-d57b-cbf33c84a4a1"
      },
      "source": [
        "lr1=LogisticRegression() #multi_class{‘auto’, ‘ovr’, ‘multinomial’}, \n",
        "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
        "\n",
        "lr1.fit(count_train1, y_train1)\n",
        "lr_pred1 = lr1.predict(count_test1)\n",
        "metrics.accuracy_score(y_test1 ,lr_pred1)\n",
        "f1_score(y_test1, lr_pred1, average=\"macro\")"
      ],
      "id": "WYOX61K1DxVs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8910517537454319"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT6UCF59BWXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b6b325-5617-4db0-9a2d-e70b975709dc"
      },
      "source": [
        "f1_score(y_test1, lr_pred1, average=\"macro\")"
      ],
      "id": "xT6UCF59BWXE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8910517537454319"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-FeWsNGAMDC"
      },
      "source": [
        "SVC"
      ],
      "id": "D-FeWsNGAMDC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9tMZDw2ALJx",
        "outputId": "7987cd33-894b-4a69-851e-1dc8fa1c4e42"
      },
      "source": [
        "#svc = SVC(kernel='linear', gamma='auto', coef0=0.0000001, tol=0.0000002)   #,random_state=78)#{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
        "svc1= SVC(kernel='linear', C=10.0, random_state=1)\n",
        "svc1.fit(count_train1, y_train1)\n",
        "sv_pred1 = svc1.predict(count_test1)\n",
        "print(metrics.accuracy_score(y_test1 ,sv_pred1))\n",
        "print(f1_score(y_test1, sv_pred1, average=\"macro\"))"
      ],
      "id": "o9tMZDw2ALJx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8746069182389937\n",
            "0.8786387495645687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RJ4rz_HNw8w"
      },
      "source": [
        "RF"
      ],
      "id": "3RJ4rz_HNw8w"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdIIqy31NveW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608c846b-90d3-489d-926f-34a8515d8513"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc1 = RandomForestClassifier()\n",
        "rfc1.fit(count_train1, y_train1)\n",
        "rfc_pred1 = rfc1.predict(count_test1)\n",
        "print(metrics.accuracy_score(y_test1 ,rfc_pred1))\n",
        "print(f1_score(y_test1, rfc_pred1, average=\"macro\"))"
      ],
      "id": "PdIIqy31NveW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8759827044025157\n",
            "0.8809954765512442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m4uewY2kE4E"
      },
      "source": [
        "### The Chosen Model Summary⏰"
      ],
      "id": "4m4uewY2kE4E"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaRkmS-SkFBJ"
      },
      "source": [
        ""
      ],
      "id": "gaRkmS-SkFBJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT5hXiFNkKp2"
      },
      "source": [
        ""
      ],
      "id": "jT5hXiFNkKp2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QR2mnfgF-nJ"
      },
      "source": [
        "### Submission"
      ],
      "id": "8QR2mnfgF-nJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ddc2688"
      },
      "source": [
        "#pred = svc.predict(count_df_test)\n",
        "pred = lr1.predict(count_df_test1)"
      ],
      "id": "1ddc2688",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acfdf860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "82952350-6b16-44fe-cfee-01496f766c80"
      },
      "source": [
        "sub = pd.DataFrame({\"tweetid\":df_test['tweetid'], 'sentiment': pred})\n",
        "sub = sub.set_index('tweetid')\n",
        "sub.to_csv('submission.csv',index=True)\n",
        "sub.head()"
      ],
      "id": "acfdf860",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweetid</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169760</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35326</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224985</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476263</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872928</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "tweetid           \n",
              "169760           1\n",
              "35326            0\n",
              "224985           1\n",
              "476263           1\n",
              "872928           0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}