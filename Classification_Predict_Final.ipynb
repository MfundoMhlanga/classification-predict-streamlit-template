{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Classification Predict Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MfundoMhlanga/classification-predict-streamlit-template/blob/master/Classification_Predict_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBPJ9hI1oPa3"
      },
      "source": [
        "#**<font color='red'>Climate Change Belief Analysis</font>**\n",
        "\n",
        "© Explore Data Science Academy\n",
        "\n",
        "Team 13\n",
        "##**<font color='green'>Introduction: Climate Change Belief</font>**\n",
        "\n",
        "<p align=\"justify\" > Many companies are built around lessening one’s environmental impact or carbon\n",
        "footprint. They offer products and services that are environmentally friendly  and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat.\n",
        "This would add to their market research efforts in gauging how their product/service may be received.\n",
        "\n",
        "##**<font color='cyan'>Problem Statement:</font>**\n",
        "\n",
        "\n",
        "\n",
        "##**<font color='purple'>Task: Classification based on Tweets</font>**\n",
        "<p align=\"justify\" > To create a Machine Learning model that is able to classify whether or not a\n",
        "person believes in climate change, based on their novel tweet data.\n",
        "Hence, providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and\n",
        "geographic categories thus increasing their insights and informing future\n",
        "marketing strategies.\n",
        "\n",
        "<div align=\"center\" style=\"width: 800px; font-size: 100%; text-align: center; margin: 0 auto\">\n",
        "<img src=\"https://raw.githubusercontent.com/MfundoMhlanga/classification-predict-streamlit-template/master/Screenshot%20(480).png\"\n",
        "\n",
        "     alt=\"Climate Change\"\n",
        "     style=\"float: center; padding-bottom=0.5em\"\n",
        "     width=600px/>\n",
        "Climate Change  Photo by <a href=\"https://explore-datascience.net\"> explore-datascience.net </a> \n",
        "</div>\n"
      ],
      "id": "uBPJ9hI1oPa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNg4G34So5B6"
      },
      "source": [
        "# Importing Packages\n",
        "\n",
        "In this section we are importing all the relavant packages which will be used for analysis and modeling."
      ],
      "id": "xNg4G34So5B6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHtZ75xBD7e_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28deab6a-a153-42e3-8caa-2c53937a8976"
      },
      "source": [
        "!!pip install nlppreprocess"
      ],
      "id": "GHtZ75xBD7e_",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting nlppreprocess',\n",
              " '  Downloading nlppreprocess-1.0.2-py3-none-any.whl (5.1 kB)',\n",
              " 'Installing collected packages: nlppreprocess',\n",
              " 'Successfully installed nlppreprocess-1.0.2']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpR60gDNFQy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72194e0-8c5f-4a37-cbff-040d1bde165a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "id": "rpR60gDNFQy1",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl7BaXRYpDN6"
      },
      "source": [
        "# Libraries for data loading, data manipulation and data visulisation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Libraries for data preparation and model building\n",
        "\n",
        "# Import the scaling module\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tabulate import tabulate \n",
        "\n",
        "# Import train/test split module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Modelling \n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "# NLP Libraries\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer,SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import pos_tag\n",
        "from nlppreprocess import NLP\n",
        "nlp = NLP()\n",
        "#evaluating the model\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "id": "Gl7BaXRYpDN6",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-whIlITEpsXI"
      },
      "source": [
        "#Loading DataSets\n",
        "\n",
        " Loading the data to be used to build our classification model."
      ],
      "id": "-whIlITEpsXI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-06-28T08:49:35.311495Z",
          "start_time": "2021-06-28T08:49:35.295494Z"
        },
        "id": "fbbb6c18"
      },
      "source": [
        "# Loading in the datasets\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/MfundoMhlanga/classification-predict-streamlit-template/master/train.csv\")\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/MfundoMhlanga/classification-predict-streamlit-template/master/test_with_no_labels.csv\")\n",
        "\n",
        "#pd.set_option('display.max_columns', None)\n",
        "df1=df.copy()\n",
        "df_test1=df_test.copy()"
      ],
      "id": "fbbb6c18",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a9902d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2b678aa9-b2ee-4b70-c635-5e836328f168"
      },
      "source": [
        "df.head(5)"
      ],
      "id": "0a9902d6",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
              "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
              "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
              "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "LuP58PdtKHbI",
        "outputId": "33d8c227-5619-428c-a59f-ad5b7bcb6b4d"
      },
      "source": [
        "df_test.head(5)"
      ],
      "id": "LuP58PdtKHbI",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>message</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Europe will now be looking to China to make sure that it is not alone in fighting climate change… https://t.co/O7T8rCgwDq</th>\n",
              "      <td>169760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Combine this with the polling of staffers re climate change and womens' rights and you have a fascist state. https://t.co/ifrm7eexpj</th>\n",
              "      <td>35326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The scary, unimpeachable evidence that climate change is already here: https://t.co/yAedqcV9Ki #itstimetochange #climatechange @ZEROCO2_;..</th>\n",
              "      <td>224985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>@Karoli @morgfair @OsborneInk @dailykos \\nPutin got to you too Jill ! \\nTrump doesn't believe in climate change at all \\nThinks it's s hoax</th>\n",
              "      <td>476263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RT @FakeWillMoore: 'Female orgasms cause global warming!'\\n-Sarcastic Republican</th>\n",
              "      <td>872928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    tweetid\n",
              "message                                                    \n",
              "Europe will now be looking to China to make sur...   169760\n",
              "Combine this with the polling of staffers re cl...    35326\n",
              "The scary, unimpeachable evidence that climate ...   224985\n",
              "@Karoli @morgfair @OsborneInk @dailykos \\nPutin...   476263\n",
              "RT @FakeWillMoore: 'Female orgasms cause global...   872928"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aheCovyTxDUA"
      },
      "source": [
        "Data Description\n",
        "\n",
        "*   Columns sentiment: Sentiment of tweet \n",
        "*   message: Tweet body\n",
        "*   tweetid: Twitter unique id\n",
        "\n",
        "i.e. We have this features: Sentiments (Target) and Message (feature) including TweetsId\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "aheCovyTxDUA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er_QIMI1vNeH",
        "outputId": "69ba8e05-025a-4419-d62d-d3069defd33a"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "id": "er_QIMI1vNeH",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH5UL_qxxYWV"
      },
      "source": [
        "Class Description \n",
        "\n",
        "\n",
        "*   2 News: the tweet links to factual news about climate change \n",
        "*   1 Pro: the tweet supports the belief of man-made climate change \n",
        "*   0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
        "*   -1 Anti: the tweet does not believe in man-made climate change \n",
        "\n",
        "\n",
        "\n",
        " \n"
      ],
      "id": "eH5UL_qxxYWV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2w7--NjyPE8"
      },
      "source": [
        "<a id=\"three\"></a>\n",
        "# Exploratory Data Analysis\n",
        "\n",
        "\n",
        "<p align=\"justify\" > This section provides an in depth EDA which allowed us to gain deeper insights into the dimensions and features of our data."
      ],
      "id": "O2w7--NjyPE8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwOi1mBtxkHe",
        "outputId": "433cc2cd-c859-4a68-f731-0fb59a42c787"
      },
      "source": [
        "#Checking the shape of the train and test set\n",
        "#df=df[:10546]\n",
        "df.shape,df_test.shape"
      ],
      "id": "fwOi1mBtxkHe",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((15819, 2), (10546, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48pfhgkCqokV",
        "outputId": "aabd535e-3c0b-4d85-c417-48153c5f4e70"
      },
      "source": [
        "round((df.isnull().sum()/df.shape[0])\n",
        "      *100,2).astype(str)+ ' %'\n"
      ],
      "id": "48pfhgkCqokV",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "message    0.0 %\n",
              "tweetid    0.0 %\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GpulHyrquJB"
      },
      "source": [
        "\n",
        "No Missing Values in our Dataset i.e. we have 0 null values on our data."
      ],
      "id": "8GpulHyrquJB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu4SY0zOqbg3",
        "outputId": "a5180801-51ce-4655-b664-e972cb521a09"
      },
      "source": [
        "df.info()"
      ],
      "id": "Gu4SY0zOqbg3",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 15819 entries, 1 to 0\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   message  15819 non-null  object\n",
            " 1   tweetid  15819 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 370.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAJ6PqRYqepD"
      },
      "source": [
        "The data types are object and 2 integers (tweetid and Sentiment) but since Sentiments is suppose to be a category, we will change it to catergory type.\n",
        "\n"
      ],
      "id": "AAJ6PqRYqepD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "BJj3WrQMyvr2",
        "outputId": "081cae09-5096-48e7-d6a0-cef0ade2c097"
      },
      "source": [
        "# Visualizing the distribution of the feature to the target\n",
        "sns.barplot(df.sentiment.value_counts().index,df.sentiment.value_counts())"
      ],
      "id": "BJj3WrQMyvr2",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4984c338d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "pTZ34NBz_8cH",
        "outputId": "2ace6fc4-eee1-4787-9507-b1125d2b8278"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels = list( {2: \"News\", 1: \"Pro\",  0: \"Neutral\", -1: \"Anti\"}.values())\n",
        "\n",
        "#my_labels = 'Tasks Pending','Tasks Ongoing','Tasks Completed'\n",
        "my_colors = ['lightblue','lightsteelblue','silver', 'red']\n",
        "my_explode = tuple([0.1] * len(labels)) #(0, 0.1, 0)\n",
        "plt.pie(df['sentiment'].value_counts(), labels=labels, autopct='%1.1f%%', startangle=10, shadow = True, colors=my_colors, explode=my_explode)\n",
        " \n",
        "\n",
        "plt.title('Tweets Categories')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "id": "pTZ34NBz_8cH",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IQ22gPx_TRs"
      },
      "source": [
        "# Data cleaning for furthur sentiment analysis\n",
        "\n",
        "def cleaner(line):\n",
        "    '''\n",
        "    For preprocessing the data, we regularize, transform each upper case into lower case, tokenize,\n",
        "    normalize and remove stopwords. Normalization transforms a token to its root word i.e. \n",
        "    These words would be transformed from \"love loving loved\" to \"love love love.\"\n",
        "    \n",
        "    '''\n",
        "\n",
        "    # Removes RT, url and trailing white spaces\n",
        "    line = re.sub(r'^RT ','', re.sub(r'https://t.co/\\w+', '', line).strip()) \n",
        "    emojis = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # removes emoticons,\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    line = emojis.sub(r'', line)\n",
        "\n",
        "    # Removes puctuation\n",
        "    punctuation = re.compile(\"[.;:!\\'’‘“”?,\\\"()\\[\\]]\")\n",
        "    tweet = punctuation.sub(\"\", line.lower()) \n",
        "    # Removes stopwords\n",
        "    nlp_for_stopwords = NLP(replace_words=True, remove_stopwords=True, \n",
        "                            remove_numbers=True, remove_punctuations=False) \n",
        "    tweet = nlp_for_stopwords.process(tweet) # This will remove stops words that are not necessary. The idea is to keep words like [is, not, was]\n",
        "    # https://towardsdatascience.com/why-you-should-avoid-removing-stopwords-aa7a353d2a52\n",
        "\n",
        "    tweet = tweet.split() \n",
        "    pos = pos_tag(tweet)\n",
        "    \n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tweet = ' '.join([lemmatizer.lemmatize(word, po[0].lower()) \n",
        "                      if (po[0].lower() in ['n', 'r', 'v', 'a'] and word[0] != '@') else word for word, po in pos])\n",
        "    return tweet"
      ],
      "id": "3IQ22gPx_TRs",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmNKWglTEnHl",
        "outputId": "41e6b670-552b-4544-a74c-43227afcc2a6"
      },
      "source": [
        "# Comparison of Tweets before we apply the function cleaner and after\n",
        "tweet = df.iloc[7,1]\n",
        "tweet_clean = cleaner(tweet)\n",
        "print('BEFORE\\n', tweet)\n",
        "print('AFTER\\n', tweet_clean)"
      ],
      "id": "wmNKWglTEnHl",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE\n",
            " RT @makeandmendlife: Six big things we can ALL do today to fight climate change, or how to be a climate activistÃ¢â‚¬Â¦ https://t.co/TYMLu6DbNM hÃ¢â‚¬Â¦\n",
            "AFTER\n",
            " @makeandmendlife six big thing we can today fight climate change how climate activistã¢â‚¬â¦ hã¢â‚¬â¦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AnFVqILulUkb",
        "outputId": "bcb0df53-e0fe-4c81-9a33-4d1b08cc7a43"
      },
      "source": [
        "df['clean']  = df['message'].apply(cleaner)\n",
        "df.head()"
      ],
      "id": "AnFVqILulUkb",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "      <td>polyscimajor epa chief not think carbon dioxid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "      <td>its not like we lack evidence anthropogenic gl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "      <td>@rawstory researcher say we three year act cli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "      <td>#todayinmaker# wire pivotal year in war climat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "      <td>@soynoviodetodas its and racist sexist climate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                              clean\n",
              "0          1  ...  polyscimajor epa chief not think carbon dioxid...\n",
              "1          1  ...  its not like we lack evidence anthropogenic gl...\n",
              "2          2  ...  @rawstory researcher say we three year act cli...\n",
              "3          1  ...  #todayinmaker# wire pivotal year in war climat...\n",
              "4          1  ...  @soynoviodetodas its and racist sexist climate...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2Hqefq9xIQkM",
        "outputId": "93f8e274-4263-4e3b-f121-2fee9bc3d058"
      },
      "source": [
        "df_test['clean']  = df_test['message'].apply(cleaner)\n",
        "df_test.head()"
      ],
      "id": "2Hqefq9xIQkM",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Europe will now be looking to China to make su...</td>\n",
              "      <td>169760</td>\n",
              "      <td>europe will now look china make sure not alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "      <td>combine with poll staffer re climate change an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The scary, unimpeachable evidence that climate...</td>\n",
              "      <td>224985</td>\n",
              "      <td>scary unimpeachable evidence climate change al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
              "      <td>476263</td>\n",
              "      <td>@karoli @morgfair @osborneink @dailykos putin ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
              "      <td>872928</td>\n",
              "      <td>@fakewillmoore female orgasm cause global warm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message  ...                                              clean\n",
              "0  Europe will now be looking to China to make su...  ...  europe will now look china make sure not alone...\n",
              "1  Combine this with the polling of staffers re c...  ...  combine with poll staffer re climate change an...\n",
              "2  The scary, unimpeachable evidence that climate...  ...  scary unimpeachable evidence climate change al...\n",
              "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...  ...  @karoli @morgfair @osborneink @dailykos putin ...\n",
              "4  RT @FakeWillMoore: 'Female orgasms cause globa...  ...  @fakewillmoore female orgasm cause global warm...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilEIqJecoNIO"
      },
      "source": [
        ""
      ],
      "id": "ilEIqJecoNIO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1C4vGQ6K_aIt",
        "outputId": "ee509869-5590-4011-d122-69b430ffb922"
      },
      "source": [
        "df=df.drop('message', axis=1)\n",
        "df_test=df_test.drop('message', axis=1)\n",
        "df_test.head()"
      ],
      "id": "1C4vGQ6K_aIt",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>169760</td>\n",
              "      <td>europe will now look china make sure not alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35326</td>\n",
              "      <td>combine with poll staffer re climate change an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>224985</td>\n",
              "      <td>scary unimpeachable evidence climate change al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>476263</td>\n",
              "      <td>@karoli @morgfair @osborneink @dailykos putin ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872928</td>\n",
              "      <td>@fakewillmoore female orgasm cause global warm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tweetid                                              clean\n",
              "0   169760  europe will now look china make sure not alone...\n",
              "1    35326  combine with poll staffer re climate change an...\n",
              "2   224985  scary unimpeachable evidence climate change al...\n",
              "3   476263  @karoli @morgfair @osborneink @dailykos putin ...\n",
              "4   872928  @fakewillmoore female orgasm cause global warm..."
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AYiwV3QdKK2"
      },
      "source": [
        "# Modelling\n",
        "#Splitting the data\n",
        "\n",
        "Split dataset into Dependent and independent variables. We are to split the dataset into dependent (Y) and independent variables (X)."
      ],
      "id": "3AYiwV3QdKK2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a12aacc1"
      },
      "source": [
        "y=df1['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(df1['message'], y, test_size=0.30, stratify=y, random_state=42)"
      ],
      "id": "a12aacc1",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_iahvQXvX5B"
      },
      "source": [
        "# init stemmer\n",
        "porter_stemmer=PorterStemmer()\n",
        "\n",
        "def my_cool_preprocessor(text):\n",
        "    \n",
        "    text=text.lower() \n",
        "    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
        "    text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n",
        "    \n",
        "    # stem words\n",
        "    words=re.split(\"\\\\s+\",text)\n",
        "    stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
        "    return ' '.join(stemmed_words)"
      ],
      "id": "o_iahvQXvX5B",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18abe2bf"
      },
      "source": [
        "#count_vectorizer = CountVectorizer(stop_words = 'english',  max_df = 0.95)\n",
        "count_vectorizer = CountVectorizer(lowercase = True, ngram_range=(1, 2), analyzer='word', max_df = 0.70, preprocessor=my_cool_preprocessor) #char_wb, word\n",
        "count_train = count_vectorizer.fit_transform(X_train.values)\n",
        "count_test = count_vectorizer.transform(X_test.values)\n",
        "count_df_test = count_vectorizer.transform(df_test1['message'].values)"
      ],
      "id": "18abe2bf",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58209445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba501c33-d2ee-45c6-fe35-69b1edb30787"
      },
      "source": [
        "count_vectorizer.get_feature_names()[:10]"
      ],
      "id": "58209445",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '00 19',\n",
              " '00 am',\n",
              " '00 appropri',\n",
              " '000',\n",
              " '000 000',\n",
              " '000 _connector_',\n",
              " '000 doctor',\n",
              " '000 farmer',\n",
              " '000 from']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJtCN27oXnk0"
      },
      "source": [
        "Tfidf Vectorizer"
      ],
      "id": "tJtCN27oXnk0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4eaf286"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.95)\n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
        "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
        "tfidf_df_test = tfidf_vectorizer.transform(df_test['clean'].values)"
      ],
      "id": "a4eaf286",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPZzAsTw1rTi"
      },
      "source": [
        "#Train Model\n",
        "After data preparation, we are now creating and training the model using Scikit-learn. We import the different classification model from skicit-learn, instantiate the model, and fit the model on the training data. We set the random state for reproducible results.\n"
      ],
      "id": "dPZzAsTw1rTi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSmCiNQPcVAL"
      },
      "source": [
        "Naive classifier"
      ],
      "id": "XSmCiNQPcVAL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yeL1aBVvosx",
        "outputId": "5c655797-fb23-4111-9df9-890f2115f064"
      },
      "source": [
        "nb_classifier = MultinomialNB().fit(count_train, y_train)\n",
        "pred = nb_classifier.predict(count_test)\n",
        "metrics.accuracy_score(y_test ,pred)\n",
        "f1_score(y_test, pred, average='macro')\n",
        "print(metrics.accuracy_score(y_test ,pred))\n",
        "print(f1_score(y_test, pred, average=\"macro\"))"
      ],
      "id": "4yeL1aBVvosx",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7050147492625368\n",
            "0.5049834781532239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqDeXJf2JQo"
      },
      "source": [
        "Random Forest"
      ],
      "id": "wGqDeXJf2JQo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85-_bkaw2IRg",
        "outputId": "afeed8f8-d3c9-49cd-bcba-f4143bff927e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier().fit(count_train, y_train)\n",
        "rfc_pred = rfc.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,rfc_pred))\n",
        "print(f1_score(y_test, rfc_pred, average=\"macro\"))"
      ],
      "id": "85-_bkaw2IRg",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.713653603034134\n",
            "0.544878635932905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6avNkMlfetZ"
      },
      "source": [
        "Logistic Regression"
      ],
      "id": "S6avNkMlfetZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuGhMIoU39wP",
        "outputId": "3cb5e507-0e83-4eaf-cafa-12d370f04b27"
      },
      "source": [
        "lr=LogisticRegression(multi_class='ovr', solver=\"sag\", random_state=100) #multi_class{‘auto’, ‘ovr’, ‘multinomial’}, \n",
        "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
        "\n",
        "lr.fit(count_train, y_train)\n",
        "lr_pred = lr.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,lr_pred))\n",
        "print(f1_score(y_test, lr_pred, average=\"macro\"))"
      ],
      "id": "WuGhMIoU39wP",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7517909818794775\n",
            "0.6550919096119828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N1XerRGBJA6T",
        "outputId": "a3f3625d-4e52-4f60-d9ac-b121aed865fd"
      },
      "source": [
        "# Creating the hyperparameter grid\n",
        "\n",
        "  \n",
        "# Instantiating logistic regression classifier\n",
        "#logreg = LogisticRegression(multi_class='multinomial', solver=\"saga\", random_state=100)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "param_grid = {\n",
        "    'C': [0.001,100] #0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'max_iter': list(range(100,800,100)),\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "  \n",
        "# Instantiating the GridSearchCV object\n",
        "logreg_cv = GridSearchCV(logreg, param_grid, refit = True, verbose = 3, cv = 5).fit(count_train, y_train)\n",
        "  \n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
        "print(\"Best score is {}\".format(logreg_cv.best_score_))\n",
        "\n",
        "\n",
        "log_pred = logreg_cv.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,log_pred))\n",
        "print(f1_score(y_test, log_pred, average=\"macro\"))"
      ],
      "id": "N1XerRGBJA6T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 490 candidates, totalling 2450 fits\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.540 total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l1, solver=saga;, score=0.539 total time=   2.7s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.2s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.1s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.0s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.8s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.9s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.602 total time=   5.0s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.597 total time=   5.2s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.591 total time=   5.1s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.596 total time=   5.1s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.9s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.602 total time=   1.4s\n",
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.606 total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.597 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.595 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.598 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.001, max_iter=100, penalty=l2, solver=saga;, score=0.600 total time=   2.1s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.540 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   5.4s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.1s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.7s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.8s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.7s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.597 total time=   5.0s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.8s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.8s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=lbfgs;, score=0.599 total time=   5.0s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=sag;, score=0.599 total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.604 total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.597 total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.593 total time=   4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.597 total time=   4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.001, max_iter=200, penalty=l2, solver=saga;, score=0.600 total time=   4.1s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.540 total time=   7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   8.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   8.0s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.0s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.7s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.8s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.7s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.8s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.591 total time=   5.0s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.7s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.8s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n",
            "[CV 1/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.603 total time=   5.6s\n",
            "[CV 2/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.598 total time=   5.8s\n",
            "[CV 3/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.592 total time=   5.8s\n",
            "[CV 4/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.597 total time=   5.5s\n",
            "[CV 5/5] END C=0.001, max_iter=300, penalty=l2, solver=saga;, score=0.599 total time=   5.9s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.540 total time=   0.4s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.540 total time=   8.3s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=   9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=  10.5s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=   0.4s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l1, solver=saga;, score=0.539 total time=   3.1s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.1s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.1s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.8s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.9s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.9s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.7s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.8s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.596 total time=   5.0s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.9s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.597 total time=   1.3s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n",
            "[CV 1/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.603 total time=   5.8s\n",
            "[CV 2/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.598 total time=   5.8s\n",
            "[CV 3/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.592 total time=   5.7s\n",
            "[CV 4/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.597 total time=   5.7s\n",
            "[CV 5/5] END C=0.001, max_iter=400, penalty=l2, solver=saga;, score=0.599 total time=   5.8s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.4s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.540 total time=   9.1s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=   0.4s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=  11.6s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=   0.5s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.1s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.597 total time=   8.9s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.591 total time=   8.9s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.6s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.6s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.9s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.9s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.9s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.6s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.7s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.597 total time=   1.2s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.591 total time=   1.2s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.596 total time=   1.1s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=sag;, score=0.599 total time=   1.2s\n",
            "[CV 1/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.603 total time=   5.4s\n",
            "[CV 2/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.598 total time=   5.3s\n",
            "[CV 3/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.592 total time=   5.6s\n",
            "[CV 4/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.597 total time=   5.3s\n",
            "[CV 5/5] END C=0.001, max_iter=500, penalty=l2, solver=saga;, score=0.599 total time=   5.4s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.540 total time=   7.9s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=   8.4s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=  10.4s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=   8.9s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l1, solver=saga;, score=0.539 total time=   2.8s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.602 total time=   8.0s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.597 total time=   9.0s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.591 total time=   9.0s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.7s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.6s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.8s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.7s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.591 total time=   4.9s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.7s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.8s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.597 total time=   1.2s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.591 total time=   1.2s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=sag;, score=0.599 total time=   1.2s\n",
            "[CV 1/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.603 total time=   5.7s\n",
            "[CV 2/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.598 total time=   5.6s\n",
            "[CV 3/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.592 total time=   5.6s\n",
            "[CV 4/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.597 total time=   5.4s\n",
            "[CV 5/5] END C=0.001, max_iter=600, penalty=l2, solver=saga;, score=0.599 total time=   5.5s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.540 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=liblinear;, score=0.539 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.540 total time=   8.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   8.8s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   0.4s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   8.3s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l1, solver=saga;, score=0.539 total time=   2.9s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.602 total time=   7.9s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.597 total time=   8.8s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.591 total time=   8.6s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.596 total time=   8.6s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=newton-cg;, score=0.599 total time=   8.7s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.602 total time=   4.7s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.597 total time=   4.8s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.591 total time=   5.0s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.596 total time=   4.9s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=lbfgs;, score=0.599 total time=   4.8s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.612 total time=   0.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.607 total time=   0.3s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.611 total time=   0.3s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.619 total time=   0.3s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=liblinear;, score=0.613 total time=   0.3s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.602 total time=   1.3s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.597 total time=   1.2s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.591 total time=   1.3s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.596 total time=   1.2s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=sag;, score=0.599 total time=   1.3s\n",
            "[CV 1/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.603 total time=   5.5s\n",
            "[CV 2/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.598 total time=   5.6s\n",
            "[CV 3/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.592 total time=   5.7s\n",
            "[CV 4/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.597 total time=   5.6s\n",
            "[CV 5/5] END C=0.001, max_iter=700, penalty=l2, solver=saga;, score=0.599 total time=   5.8s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.587 total time=   0.7s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.577 total time=   0.8s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=liblinear;, score=0.585 total time=   0.7s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.586 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.584 total time=   2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.586 total time=   2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.584 total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l1, solver=saga;, score=0.590 total time=   2.8s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.4s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.8s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.8s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.7s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.7s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.3s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.3s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.1s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.6s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs;, score=0.691 total time=   7.8s\n",
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.674 total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.682 total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.696 total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.696 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=sag;, score=0.691 total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.676 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.684 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.697 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.696 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=100, penalty=l2, solver=saga;, score=0.690 total time=   2.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.577 total time=   0.6s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=liblinear;, score=0.585 total time=   0.6s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.586 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.584 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.585 total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.584 total time=   5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l1, solver=saga;, score=0.590 total time=   5.3s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.4s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.6s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.5s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.6s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.2s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.6s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.1s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.6s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.3s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.660 total time=   0.4s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.697 total time=   2.1s\n",
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.676 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.682 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.696 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.698 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=200, penalty=l2, solver=saga;, score=0.691 total time=   4.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.591 total time=   0.6s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.577 total time=   0.6s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=liblinear;, score=0.585 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.584 total time=   7.2s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.585 total time=   7.6s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.585 total time=   6.7s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l1, solver=saga;, score=0.591 total time=   7.1s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.5s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.8s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.6s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.6s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.1s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.5s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.2s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.8s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.2s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.681 total time=   0.5s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.682 total time=   2.2s\n",
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.697 total time=   2.3s\n",
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.696 total time=   2.2s\n",
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=sag;, score=0.691 total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.674 total time=   6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.683 total time=   6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.697 total time=   6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.696 total time=   5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.01, max_iter=300, penalty=l2, solver=saga;, score=0.691 total time=   5.9s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.587 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.577 total time=   0.8s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=liblinear;, score=0.585 total time=   0.7s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.585 total time=   7.3s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.584 total time=   6.3s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l1, solver=saga;, score=0.591 total time=   6.7s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.2s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.7s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.6s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.674 total time=   7.8s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.7s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.4s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.5s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.1s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.660 total time=   0.4s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.665 total time=   0.4s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.686 total time=   0.5s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.674 total time=   2.2s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.697 total time=   2.1s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.674 total time=   7.2s\n",
            "[CV 2/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.683 total time=   6.8s\n",
            "[CV 3/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.697 total time=   7.3s\n",
            "[CV 4/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.696 total time=   7.3s\n",
            "[CV 5/5] END C=0.01, max_iter=400, penalty=l2, solver=saga;, score=0.692 total time=   7.2s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.591 total time=   0.7s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.577 total time=   0.8s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.588 total time=   0.7s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.585 total time=   0.6s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.587 total time=   6.9s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.584 total time=   6.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.585 total time=   7.1s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.584 total time=   6.2s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.591 total time=   6.7s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.2s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.6s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.5s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.6s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.1s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.6s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.5s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.7s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.1s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.686 total time=   0.5s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.681 total time=   0.5s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.682 total time=   2.2s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.697 total time=   2.2s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.696 total time=   2.2s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.674 total time=   7.4s\n",
            "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.683 total time=   6.9s\n",
            "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.697 total time=   7.2s\n",
            "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.696 total time=   7.2s\n",
            "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.692 total time=   7.1s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.591 total time=   0.6s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.587 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.577 total time=   0.6s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.588 total time=   0.6s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=liblinear;, score=0.585 total time=   0.6s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.584 total time=   6.9s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.585 total time=   7.3s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.584 total time=   6.1s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l1, solver=saga;, score=0.591 total time=   6.7s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.3s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.4s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.5s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.3s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.4s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.4s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.3s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.2s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.660 total time=   0.5s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.686 total time=   0.5s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.674 total time=   2.2s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.697 total time=   2.1s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.674 total time=   7.5s\n",
            "[CV 2/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.683 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.697 total time=   7.2s\n",
            "[CV 4/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.696 total time=   7.5s\n",
            "[CV 5/5] END C=0.01, max_iter=600, penalty=l2, solver=saga;, score=0.692 total time=   7.2s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.591 total time=   0.6s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.587 total time=   0.6s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.577 total time=   0.7s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.588 total time=   0.8s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=liblinear;, score=0.585 total time=   0.7s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.587 total time=   6.8s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.584 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.585 total time=   7.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.584 total time=   6.2s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l1, solver=saga;, score=0.591 total time=   6.9s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.674 total time=  11.3s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.682 total time=  12.6s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.697 total time=  11.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.696 total time=  11.4s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=newton-cg;, score=0.691 total time=  11.5s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.674 total time=   8.5s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.682 total time=   8.3s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.697 total time=   8.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.696 total time=   8.9s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=lbfgs;, score=0.691 total time=   8.2s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.660 total time=   0.4s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.665 total time=   0.5s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.686 total time=   0.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.681 total time=   0.4s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=liblinear;, score=0.680 total time=   0.5s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.674 total time=   2.3s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.682 total time=   2.1s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.697 total time=   2.2s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.696 total time=   2.1s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=sag;, score=0.691 total time=   2.2s\n",
            "[CV 1/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.674 total time=   7.4s\n",
            "[CV 2/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.683 total time=   7.0s\n",
            "[CV 3/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.697 total time=   7.4s\n",
            "[CV 4/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.696 total time=   7.4s\n",
            "[CV 5/5] END C=0.01, max_iter=700, penalty=l2, solver=saga;, score=0.692 total time=   7.4s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.667 total time=   0.8s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.656 total time=   0.9s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.688 total time=   0.9s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.679 total time=   0.9s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=liblinear;, score=0.686 total time=   0.9s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.674 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.666 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.690 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.689 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l1, solver=saga;, score=0.693 total time=   3.7s\n",
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.738 total time=  16.7s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.732 total time=  16.4s\n",
            "[CV 3/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.749 total time=  17.9s\n",
            "[CV 4/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.749 total time=  17.6s\n",
            "[CV 5/5] END C=0.1, max_iter=100, penalty=l2, solver=newton-cg;, score=0.741 total time=  17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.738 total time=  17.2s\n",
            "[CV 2/5] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs;, score=0.732 total time=  17.5s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-5071e5fc010e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Instantiating the GridSearchCV object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlogreg_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Print the tuned parameters and score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             )\n\u001b[1;32m    814\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"newton-cg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmatmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    568\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    569\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;31m####################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvecs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[0;32m--> 487\u001b[0;31m            other.ravel(), result.ravel())\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX8_ZNC6fcrO",
        "outputId": "46f0ac99-df52-412f-dc62-2df1152d3518"
      },
      "source": [
        "lr=LogisticRegression(multi_class='multinomial', solver=\"saga\", random_state=100) #multi_class{‘auto’, ‘ovr’, ‘multinomial’}, \n",
        "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
        "\n",
        "lr.fit(count_train, y_train)\n",
        "lr_pred = lr.predict(count_test)\n",
        "metrics.accuracy_score(y_test ,lr_pred)\n"
      ],
      "id": "gX8_ZNC6fcrO",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7498946481247366"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oixccybdfcun",
        "outputId": "7c4305ff-0ada-4d21-fc65-f84e2fbd367e"
      },
      "source": [
        "f1_score(y_test, lr_pred, average=\"macro\")"
      ],
      "id": "oixccybdfcun",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6557587686600752"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8YPR6Nppbg2"
      },
      "source": [
        "Ridge Classifier"
      ],
      "id": "i8YPR6Nppbg2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMAesUV2pZC4",
        "outputId": "59859dba-693f-4b10-c0a3-5856d5c170a1"
      },
      "source": [
        "rc = RidgeClassifier()\n",
        "\n",
        "rrc=RidgeClassifier(alpha=1.0, solver='auto',tol=0.001).fit(count_train, y_train) #(alpha=1.0, solver='auto',tol=0.001).fit(count_train, y_train)\n",
        "#{‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’, ‘lbfgs’}\n",
        "\n",
        "rcc_pred = rrc.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,rcc_pred))\n",
        "print(f1_score(y_test, rcc_pred, average=\"macro\"))"
      ],
      "id": "oMAesUV2pZC4",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7458912768647282\n",
            "0.6596918744157119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdOR0HOv0foX",
        "outputId": "eee9121f-bbcb-4ef3-930f-4ff3006b2dbf"
      },
      "source": [
        "\n",
        "rrc=RidgeClassifier(alpha=10, solver='cholesky',tol=0.08, fit_intercept=False).fit(count_train, y_train) #(alpha=1.0, solver='auto',tol=0.001).fit(count_train, y_train)\n",
        "#{‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’, ‘lbfgs’}\n",
        "\n",
        "rcc_pred = rrc.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,rcc_pred))\n",
        "print(f1_score(y_test, rcc_pred, average=\"macro\"))"
      ],
      "id": "bdOR0HOv0foX",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7511588706278972\n",
            "0.6528527500795417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h02o7Dv0LGx",
        "outputId": "294e3394-1083-4502-8a6e-96bc63a0737a"
      },
      "source": [
        "model = RidgeClassifier()\n",
        "alpha = [0.1, 0.2, 0.9, 1.0]\n",
        "# define grid search\n",
        "grid = dict(alpha=alpha)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "ridge = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0).fit(count_train, y_train)\n",
        "ridge_pred = ridge.predict(count_test)\n",
        "metrics.accuracy_score(y_test ,ridge_pred)"
      ],
      "id": "7h02o7Dv0LGx",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7458912768647282"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI3gRN3epZFo",
        "outputId": "93f200ed-da5f-4a28-ec4a-6144b22eae7c"
      },
      "source": [
        "f1_score(y_test, lr_pred, average=\"macro\")"
      ],
      "id": "VI3gRN3epZFo",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6557587686600752"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_44kZybQqIqL"
      },
      "source": [
        "MLP Classifier"
      ],
      "id": "_44kZybQqIqL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20NeKMP1qI5X",
        "outputId": "6cd558cd-ad0c-4223-ff65-bfc7d40ff2aa"
      },
      "source": [
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,50,30),\n",
        "                        max_iter = 10,activation = 'tanh',\n",
        "                        solver = 'adam').fit(count_train, y_train)\n",
        "\n",
        "mlp_pred = mlp_clf.predict(count_test)\n",
        "\n",
        "print(metrics.accuracy_score(y_test ,mlp_pred))\n",
        "print(f1_score(y_test, mlp_pred, average=\"macro\"))\n"
      ],
      "id": "20NeKMP1qI5X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7488411293721028\n",
            "0.6627649692352936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoLWq-O0qJGo"
      },
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30)],\n",
        "    'max_iter': [50, 100, 150],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "grid = GridSearchCV(mlp_clf, param_grid, n_jobs= -1, cv=5)\n",
        "grid.fit(count_train, y_train)\n",
        "\n",
        "print(grid.best_params_) \n",
        "\n",
        "\n",
        "grid_predictions = grid.predict(count_test)"
      ],
      "id": "BoLWq-O0qJGo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKjbLLd1F3Wq"
      },
      "source": [
        "SVC"
      ],
      "id": "iKjbLLd1F3Wq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0d84867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471216fd-6bad-478e-a324-fd211b7e017e"
      },
      "source": [
        "#svc = SVC(kernel='linear', gamma='auto', coef0=0.0000001, tol=0.0000002)   #,random_state=78)#{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
        "svc= SVC(kernel='rbf', C=10.0, random_state=1).fit(count_train, y_train)\n",
        "sv_pred = svc.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,sv_pred))\n",
        "print(f1_score(y_test, sv_pred, average=\"macro\"))"
      ],
      "id": "b0d84867",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7475769068689423\n",
            "0.6425191948546116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXbVfDwwrwaf"
      },
      "source": [
        "Linear SVC"
      ],
      "id": "TXbVfDwwrwaf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V07MFIwZEN-V",
        "outputId": "a2cef75b-716c-49de-8ca5-a95ca1585fe7"
      },
      "source": [
        "svc = svm.LinearSVC().fit(count_train, y_train)\n",
        "sv_pred = svc.predict(count_test)\n",
        "print(metrics.accuracy_score(y_test ,sv_pred))\n",
        "print(f1_score(y_test, sv_pred, average=\"macro\"))"
      ],
      "id": "V07MFIwZEN-V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7511588706278972\n",
            "0.6638012039186718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83741bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c07ec82-4b67-4790-dd0d-a2fee7e376ff"
      },
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_test, y_pred=sv_pred, labels=[-1, 0, 1, 2])\n",
        "conf_matrix"
      ],
      "id": "83741bdd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  64,   22,  173,   19],\n",
              "       [   3,  158,  242,   22],\n",
              "       [   3,   52, 1555,  145],\n",
              "       [   3,    8,  160,  535]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17d7c12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5ee97c76-2ef6-489d-9b7f-4cd60e4cd5b1"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.seismic, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "id": "17d7c12e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke9S3DGFYxpe"
      },
      "source": [
        "#Evaluating Models i.e Making Predictions on the Test Set:"
      ],
      "id": "Ke9S3DGFYxpe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFFo7TGrYs1-"
      },
      "source": [
        "# evaluate one or more ML models\n",
        "\n",
        "# Make training set predictions for each model\n",
        "pred_train_nb = nb_classifier.predict(count_train)  \n",
        "pred_test_nb = nb_classifier.predict(count_test) \n",
        "\n",
        "\n",
        "pred_train_rfc = rfc.predict(count_train) \n",
        "pred_test_rfc= rfc.predict(count_test)\n",
        "\n",
        "pred_train_lr = lr.predict(count_train) \n",
        "pred_test_lr= lr.predict(count_test)\n",
        "\n",
        "\n",
        "pred_train_rrc = rrc.predict(count_train) \n",
        "pred_test_rrc= rrc.predict(count_test)\n",
        "\n",
        "pred_train_mlp= mlp_clf.predict(count_train) \n",
        "pred_test_mlp= mlp_clf.predict(count_test)\n",
        "\n",
        "pred_train_svc= svc.predict(count_train) \n",
        "pred_test_svc= svc.predict(count_test)\n",
        "\n"
      ],
      "id": "mFFo7TGrYs1-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE-4gIKBrLFA"
      },
      "source": [
        "# Comparing Model Performance: \n",
        "\n",
        "The Model is tested using and Error metrics which  enables us to track the efficiency and accuracy. The metrics we are using is called the F1_score. "
      ],
      "id": "YE-4gIKBrLFA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Je3Zmo4r9Dt"
      },
      "source": [
        "Formula\n",
        "\n"
      ],
      "id": "6Je3Zmo4r9Dt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK39-qybrLUw"
      },
      "source": [
        "### Model Performance Accuracy"
      ],
      "id": "wK39-qybrLUw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcQKPQBJZ8ru"
      },
      "source": [
        "# Compare model performance\n",
        "\n",
        "# Dictionary of results\n",
        "results_dict = {'Training accuracy_score':\n",
        "                    {\n",
        "                        \"Naive B\": metrics.accuracy_score(y_train ,pred_train_nb), \n",
        "                        \"FOREST\": metrics.accuracy_score(y_train ,pred_train_rfc),\n",
        "                        \"Logistic\":metrics.accuracy_score(y_train ,pred_train_lr),\n",
        "                        \"Ridge Classifier\": metrics.accuracy_score(y_train ,pred_train_rrc),\n",
        "                        \"MLP Classifier\": metrics.accuracy_score(y_train ,pred_train_mlp),\n",
        "                        \"Support Vector Classifier\": metrics.accuracy_score(y_train ,pred_train_svc)\n",
        "                      \n",
        "                     \n",
        "                     \n",
        "                    },\n",
        "                    'Test accuracy_score':\n",
        "                    {\n",
        "                        \"Naive B\": metrics.accuracy_score(y_test ,pred_test_nb),\n",
        "                        \"FOREST\": metrics.accuracy_score(y_test ,pred_test_rfc),\n",
        "                        \"Logistic\": metrics.accuracy_score(y_test ,pred_test_lr),\n",
        "                        \"Ridge Classifier\": metrics.accuracy_score(y_test ,pred_test_rrc),\n",
        "                        \"MLP Classifier\": metrics.accuracy_score(y_test,pred_test_mlp),\n",
        "                        \"Support Vector Classifier\": metrics.accuracy_score(y_test ,pred_test_svc)\n",
        "                    }\n",
        "                }\n"
      ],
      "id": "EcQKPQBJZ8ru",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNEiWqO_rrSr"
      },
      "source": [
        "### Model Performance F1_score"
      ],
      "id": "eNEiWqO_rrSr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUwY1CJ6onga"
      },
      "source": [
        "# Dictionary of results\n",
        "results_dict_scores = {'F1_score':\n",
        "                    {\n",
        "                        \"Naive B\": f1_score(y_test, pred_test_nb, average=\"macro\"), \n",
        "                        \"FOREST\": f1_score(y_test, pred_test_rfc, average=\"macro\"),\n",
        "                        \"Logistic\":f1_score(y_test, pred_test_lr, average=\"macro\"),\n",
        "                        \"Ridge Classifier\": f1_score(y_test, pred_test_rrc, average=\"macro\"),\n",
        "                        \"MLP Classifier\": f1_score(y_test, pred_test_mlp, average=\"macro\"),\n",
        "                        \"Support Vector Classifier\": f1_score(y_test, pred_test_svc, average=\"macro\")\n",
        "\n",
        "                    }\n",
        "                  \n",
        "                }"
      ],
      "id": "gUwY1CJ6onga",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q69DTvTJrZcD"
      },
      "source": [
        "# Results of all the models\n",
        "The results of the models are summarized and shown with regards to the Training and Testing RMSE."
      ],
      "id": "Q69DTvTJrZcD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjpliRFbseqV"
      },
      "source": [
        "### Results Based on Accuracy"
      ],
      "id": "vjpliRFbseqV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1V_D7XImRY1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "d93970ea-d82d-4549-cd3c-f96f7c2cea4e"
      },
      "source": [
        "# Create dataframe from the dictionary of all the accuracy score results\n",
        "results_df = pd.DataFrame(data=results_dict)\n",
        "results_df"
      ],
      "id": "O1V_D7XImRY1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training accuracy_score</th>\n",
              "      <th>Test accuracy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Naive B</th>\n",
              "      <td>0.940034</td>\n",
              "      <td>0.705015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOREST</th>\n",
              "      <td>0.999910</td>\n",
              "      <td>0.713864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic</th>\n",
              "      <td>0.999729</td>\n",
              "      <td>0.749895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge Classifier</th>\n",
              "      <td>0.998194</td>\n",
              "      <td>0.751159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP Classifier</th>\n",
              "      <td>0.999910</td>\n",
              "      <td>0.748841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Classifier</th>\n",
              "      <td>0.999910</td>\n",
              "      <td>0.751159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           Training accuracy_score  Test accuracy_score\n",
              "Naive B                                   0.940034             0.705015\n",
              "FOREST                                    0.999910             0.713864\n",
              "Logistic                                  0.999729             0.749895\n",
              "Ridge Classifier                          0.998194             0.751159\n",
              "MLP Classifier                            0.999910             0.748841\n",
              "Support Vector Classifier                 0.999910             0.751159"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yCTaRhmrb1g"
      },
      "source": [
        "### Results Based on F1_score"
      ],
      "id": "6yCTaRhmrb1g"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKvN8JT0rBVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "109dc8c7-7394-4fc4-e5ab-53233f43e879"
      },
      "source": [
        "results_f1score = pd.DataFrame(data=results_dict_scores)\n",
        "results_f1score"
      ],
      "id": "BKvN8JT0rBVc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FOREST</th>\n",
              "      <td>0.544633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic</th>\n",
              "      <td>0.655759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP Classifier</th>\n",
              "      <td>0.662765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive B</th>\n",
              "      <td>0.504983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge Classifier</th>\n",
              "      <td>0.652853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Classifier</th>\n",
              "      <td>0.663801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           F1_score\n",
              "FOREST                     0.544633\n",
              "Logistic                   0.655759\n",
              "MLP Classifier             0.662765\n",
              "Naive B                    0.504983\n",
              "Ridge Classifier           0.652853\n",
              "Support Vector Classifier  0.663801"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dln8kfsfHFH"
      },
      "source": [
        "###Models Consolidated"
      ],
      "id": "-Dln8kfsfHFH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27IshfJQeKg4",
        "outputId": "858305b9-de2e-46bd-a275-e5336d1e2784"
      },
      "source": [
        "# Creating a list of all the models to train\n",
        "Classifiers = [MultinomialNB(),RandomForestClassifier(), LogisticRegression(multi_class='ovr', solver=\"sag\", random_state=100), RidgeClassifier(alpha=1.0, solver='auto',tol=0.001), MLPClassifier(hidden_layer_sizes=(100,50,30),\n",
        "                        max_iter = 10,activation = 'tanh',\n",
        "                        solver = 'adam'), SVC(kernel = 'linear'), SVC(kernel = 'rbf'), DecisionTreeClassifier()]\n",
        "\n",
        "\n",
        "for n in range(0, len(Classifiers)):\n",
        "    text_clf = Pipeline([('clf', Classifiers[n])])\n",
        "    text_clf.fit(count_train, y_train)  \n",
        "    predictions = text_clf.predict(count_test)\n",
        "    \n",
        "    print(Classifiers[n])\n",
        "    print(metrics.confusion_matrix(y_test,predictions))\n",
        "    print(metrics.classification_report(y_test,predictions))\n",
        "    print('F1_score: ',metrics.f1_score(y_test,predictions, average = 'macro'))\n",
        "    print('New Model\\n')"
      ],
      "id": "27IshfJQeKg4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n",
            "[[  53    2  323   11]\n",
            " [   2  102  565   37]\n",
            " [   0    4 2445  110]\n",
            " [   2    0  344  746]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.93      0.14      0.24       389\n",
            "           0       0.94      0.14      0.25       706\n",
            "           1       0.66      0.96      0.78      2559\n",
            "           2       0.83      0.68      0.75      1092\n",
            "\n",
            "    accuracy                           0.71      4746\n",
            "   macro avg       0.84      0.48      0.50      4746\n",
            "weighted avg       0.77      0.71      0.65      4746\n",
            "\n",
            "F1_score:  0.5049834781532239\n",
            "New Model\n",
            "\n",
            "RandomForestClassifier()\n",
            "[[  62   30  283   14]\n",
            " [   1  185  478   42]\n",
            " [   2   31 2390  136]\n",
            " [   2    7  330  753]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.93      0.16      0.27       389\n",
            "           0       0.73      0.26      0.39       706\n",
            "           1       0.69      0.93      0.79      2559\n",
            "           2       0.80      0.69      0.74      1092\n",
            "\n",
            "    accuracy                           0.71      4746\n",
            "   macro avg       0.79      0.51      0.55      4746\n",
            "weighted avg       0.74      0.71      0.68      4746\n",
            "\n",
            "F1_score:  0.5471154117940583\n",
            "New Model\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(multi_class='ovr', random_state=100, solver='sag')\n",
            "[[ 152   49  169   19]\n",
            " [  30  301  319   56]\n",
            " [  21  102 2244  192]\n",
            " [   6   14  201  871]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.73      0.39      0.51       389\n",
            "           0       0.65      0.43      0.51       706\n",
            "           1       0.77      0.88      0.82      2559\n",
            "           2       0.77      0.80      0.78      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.73      0.62      0.66      4746\n",
            "weighted avg       0.74      0.75      0.74      4746\n",
            "\n",
            "F1_score:  0.6550919096119828\n",
            "New Model\n",
            "\n",
            "RidgeClassifier()\n",
            "[[ 159   63  148   19]\n",
            " [  24  339  291   52]\n",
            " [  23  127 2194  215]\n",
            " [   6   33  205  848]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.75      0.41      0.53       389\n",
            "           0       0.60      0.48      0.53       706\n",
            "           1       0.77      0.86      0.81      2559\n",
            "           2       0.75      0.78      0.76      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.72      0.63      0.66      4746\n",
            "weighted avg       0.74      0.75      0.74      4746\n",
            "\n",
            "F1_score:  0.6596918744157119\n",
            "New Model\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50, 30), max_iter=10)\n",
            "[[ 160   68  144   17]\n",
            " [  23  337  295   51]\n",
            " [  20  159 2211  169]\n",
            " [   6   24  210  852]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.77      0.41      0.54       389\n",
            "           0       0.57      0.48      0.52       706\n",
            "           1       0.77      0.86      0.82      2559\n",
            "           2       0.78      0.78      0.78      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.72      0.63      0.66      4746\n",
            "weighted avg       0.74      0.75      0.74      4746\n",
            "\n",
            "F1_score:  0.6633233226003652\n",
            "New Model\n",
            "\n",
            "SVC(kernel='linear')\n",
            "[[ 171   63  141   14]\n",
            " [  34  356  281   35]\n",
            " [  40  153 2181  185]\n",
            " [   5   31  187  869]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.68      0.44      0.54       389\n",
            "           0       0.59      0.50      0.54       706\n",
            "           1       0.78      0.85      0.82      2559\n",
            "           2       0.79      0.80      0.79      1092\n",
            "\n",
            "    accuracy                           0.75      4746\n",
            "   macro avg       0.71      0.65      0.67      4746\n",
            "weighted avg       0.75      0.75      0.75      4746\n",
            "\n",
            "F1_score:  0.671604250620598\n",
            "New Model\n",
            "\n",
            "SVC()\n",
            "[[  74   50  236   29]\n",
            " [   9  251  358   88]\n",
            " [   5   64 2217  273]\n",
            " [   1   11  175  905]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.83      0.19      0.31       389\n",
            "           0       0.67      0.36      0.46       706\n",
            "           1       0.74      0.87      0.80      2559\n",
            "           2       0.70      0.83      0.76      1092\n",
            "\n",
            "    accuracy                           0.73      4746\n",
            "   macro avg       0.74      0.56      0.58      4746\n",
            "weighted avg       0.73      0.73      0.70      4746\n",
            "\n",
            "F1_score:  0.5828730918621633\n",
            "New Model\n",
            "\n",
            "KNeighborsClassifier()\n",
            "[[  44  285   58    2]\n",
            " [   6  601   91    8]\n",
            " [  38 1469  995   57]\n",
            " [  11  474  348  259]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.11      0.18       389\n",
            "           0       0.21      0.85      0.34       706\n",
            "           1       0.67      0.39      0.49      2559\n",
            "           2       0.79      0.24      0.37      1092\n",
            "\n",
            "    accuracy                           0.40      4746\n",
            "   macro avg       0.53      0.40      0.34      4746\n",
            "weighted avg       0.61      0.40      0.41      4746\n",
            "\n",
            "F1_score:  0.3442240332681083\n",
            "New Model\n",
            "\n",
            "DecisionTreeClassifier()\n",
            "[[ 107   66  190   26]\n",
            " [  29  249  356   72]\n",
            " [  76  191 2033  259]\n",
            " [  19   37  284  752]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.46      0.28      0.35       389\n",
            "           0       0.46      0.35      0.40       706\n",
            "           1       0.71      0.79      0.75      2559\n",
            "           2       0.68      0.69      0.68      1092\n",
            "\n",
            "    accuracy                           0.66      4746\n",
            "   macro avg       0.58      0.53      0.54      4746\n",
            "weighted avg       0.65      0.66      0.65      4746\n",
            "\n",
            "F1_score:  0.5442784524065772\n",
            "New Model\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1SPa163BWOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "533a4ed5-2855-4480-eee2-b1c0fa065dc2"
      },
      "source": [
        "#pred = svc.predict(count_df_test)\n",
        "pred = rrc.predict(count_df_test)\n",
        "sub = pd.DataFrame({\"tweetid\":df_test['tweetid'], 'sentiment': pred})\n",
        "sub = sub.set_index('tweetid')\n",
        "sub.to_csv('submission.csv',index=True)\n",
        "sub.head()"
      ],
      "id": "E1SPa163BWOH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweetid</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169760</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35326</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224985</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476263</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872928</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "tweetid           \n",
              "169760           2\n",
              "35326            1\n",
              "224985           1\n",
              "476263           1\n",
              "872928           0"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBnCEhBoc-C4"
      },
      "source": [
        "##Training and Testing Our data on balanced Dataset"
      ],
      "id": "PBnCEhBoc-C4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_adQ7OYL7Dh"
      },
      "source": [
        "###Class Imbalance Data "
      ],
      "id": "5_adQ7OYL7Dh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWUXdrcidT7",
        "outputId": "2a7f4092-6f62-422c-8c61-b4702b71600f"
      },
      "source": [
        "data = df.copy()\n",
        "data['sentiment'].value_counts()"
      ],
      "id": "6xWUXdrcidT7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVA2bltJidWd",
        "outputId": "682216a6-6530-47ca-dde3-6d7855fd7a56"
      },
      "source": [
        "# There are more instances of class 1 than class 2, class 0 and Class -1 in the data frame df.  \n",
        "\n",
        "# Separate the classes\n",
        "Cat_News = data[data['sentiment']==2]\n",
        "cat_Pro = data[data['sentiment']==1]\n",
        "cat_Neutral = data[data['sentiment']==0]\n",
        "cat_Anti= data[data['sentiment']==-1]\n",
        "\n",
        "# Upsample minority class to match the Majority Class\n",
        "Cat_News = resample(Cat_News,\n",
        "                             replace=True,  # sample with replacement\n",
        "                             n_samples=8530,  # to match majority class\n",
        "                             random_state=300)  # reproducible results\n",
        "cat_Neutral = resample(cat_Neutral,\n",
        "                             replace=True,  # sample with replacement\n",
        "                             n_samples=8530,  # to match majority class\n",
        "                             random_state=300)  # reproducible results\n",
        "cat_Anti = resample(cat_Anti,\n",
        "                             replace=True,  # sample with replacement\n",
        "                             n_samples=8530,  # to match majority class\n",
        "                             random_state=300)  # reproducible results\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "# Display new class counts\n",
        "\n",
        "Balanced = pd.concat([cat_Pro, Cat_News, cat_Neutral,cat_Anti])\n",
        "Balanced['sentiment'].value_counts()"
      ],
      "id": "rVA2bltJidWd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    8530\n",
              " 2    8530\n",
              " 1    8530\n",
              " 0    8530\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTxOPjzXB4sd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "effb6e0c-d17b-4aef-8f95-b3562b941c81"
      },
      "source": [
        "# Checking if data has been well-balanced\n",
        "sns.countplot(x = Balanced['sentiment'], data = data, palette='tab10')\n",
        "plt.title('Balanced Data')\n",
        "plt.show()"
      ],
      "id": "vTxOPjzXB4sd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCd79CDtBWRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511038da-96b3-435f-f9db-061c154673ae"
      },
      "source": [
        "#Working with balanced data\n",
        "\n",
        "# Defining the features as well as the label\n",
        "X_new= Balanced['clean']\n",
        "#X_new = X_new.apply(cleaner)\n",
        "X_new=Balanced['clean']\n",
        "y_new = Balanced['sentiment']\n",
        "\n",
        "#Train and Test Split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_new, y_new, test_size=0.40, stratify=y_new,random_state=42)\n",
        "\n",
        "count_vectorizer = CountVectorizer(lowercase = True, ngram_range=(1, 2), analyzer='word', max_df = 0.70, preprocessor=my_cool_preprocessor)#(lowercase = True, ngram_range=(1, 2), analyzer='word')\n",
        "count_train1 = count_vectorizer.fit_transform(X_train1.values)\n",
        "count_test1 = count_vectorizer.transform(X_test1.values)\n",
        "count_df_test1 = count_vectorizer.transform(df_test['clean'].values)\n",
        "\n",
        "\n",
        "for n in range(0, len(Classifiers)):\n",
        "    text_clf = Pipeline([('clf', Classifiers[n])])\n",
        "    text_clf.fit(count_train1, y_train1)  \n",
        "    predictions = text_clf.predict(count_test1)\n",
        "    \n",
        "    \n",
        "    print(Classifiers[n])\n",
        "    print(metrics.confusion_matrix(y_test1,predictions))\n",
        "    print(metrics.classification_report(y_test1,predictions))\n",
        "    print('F1_score: ',round(metrics.f1_score(y_test1,predictions, average = 'macro'),3))\n",
        "    print('-------------------------------------------------------')"
      ],
      "id": "FCd79CDtBWRO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n",
            "[[3347   24   18   23]\n",
            " [ 145 3068  122   77]\n",
            " [ 253  309 2430  420]\n",
            " [  51   34  122 3205]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.88      0.98      0.93      3412\n",
            "           0       0.89      0.90      0.90      3412\n",
            "           1       0.90      0.71      0.80      3412\n",
            "           2       0.86      0.94      0.90      3412\n",
            "\n",
            "    accuracy                           0.88     13648\n",
            "   macro avg       0.88      0.88      0.88     13648\n",
            "weighted avg       0.88      0.88      0.88     13648\n",
            "\n",
            "F1_score:  0.88\n",
            "-------------------------------------------------------\n",
            "RandomForestClassifier()\n",
            "[[3357   27   28    0]\n",
            " [  26 3263  106   17]\n",
            " [  75  361 2561  415]\n",
            " [  18   66  147 3181]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.98      0.97      3412\n",
            "           0       0.88      0.96      0.92      3412\n",
            "           1       0.90      0.75      0.82      3412\n",
            "           2       0.88      0.93      0.91      3412\n",
            "\n",
            "    accuracy                           0.91     13648\n",
            "   macro avg       0.91      0.91      0.90     13648\n",
            "weighted avg       0.91      0.91      0.90     13648\n",
            "\n",
            "F1_score:  0.904\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(multi_class='ovr', random_state=100, solver='sag')\n",
            "[[3368   33   11    0]\n",
            " [  31 3267   88   26]\n",
            " [  93  321 2642  356]\n",
            " [  17   51  111 3233]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.99      0.97      3412\n",
            "           0       0.89      0.96      0.92      3412\n",
            "           1       0.93      0.77      0.84      3412\n",
            "           2       0.89      0.95      0.92      3412\n",
            "\n",
            "    accuracy                           0.92     13648\n",
            "   macro avg       0.92      0.92      0.91     13648\n",
            "weighted avg       0.92      0.92      0.91     13648\n",
            "\n",
            "F1_score:  0.915\n",
            "-------------------------------------------------------\n",
            "RidgeClassifier()\n",
            "[[3368   29   12    3]\n",
            " [  30 3257  102   23]\n",
            " [  73  303 2677  359]\n",
            " [  13   59  142 3198]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.99      0.98      3412\n",
            "           0       0.89      0.95      0.92      3412\n",
            "           1       0.91      0.78      0.84      3412\n",
            "           2       0.89      0.94      0.91      3412\n",
            "\n",
            "    accuracy                           0.92     13648\n",
            "   macro avg       0.92      0.92      0.91     13648\n",
            "weighted avg       0.92      0.92      0.91     13648\n",
            "\n",
            "F1_score:  0.914\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50, 30), max_iter=10)\n",
            "[[3371   29   12    0]\n",
            " [  39 3232  129   12]\n",
            " [  78  243 2840  251]\n",
            " [  23   54  166 3169]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.99      0.97      3412\n",
            "           0       0.91      0.95      0.93      3412\n",
            "           1       0.90      0.83      0.87      3412\n",
            "           2       0.92      0.93      0.93      3412\n",
            "\n",
            "    accuracy                           0.92     13648\n",
            "   macro avg       0.92      0.92      0.92     13648\n",
            "weighted avg       0.92      0.92      0.92     13648\n",
            "\n",
            "F1_score:  0.923\n",
            "-------------------------------------------------------\n",
            "SVC(kernel='linear')\n",
            "[[3361   34   17    0]\n",
            " [  30 3269  100   13]\n",
            " [  85  355 2673  299]\n",
            " [  12   79  139 3182]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.99      0.97      3412\n",
            "           0       0.87      0.96      0.91      3412\n",
            "           1       0.91      0.78      0.84      3412\n",
            "           2       0.91      0.93      0.92      3412\n",
            "\n",
            "    accuracy                           0.91     13648\n",
            "   macro avg       0.92      0.91      0.91     13648\n",
            "weighted avg       0.92      0.91      0.91     13648\n",
            "\n",
            "F1_score:  0.913\n",
            "-------------------------------------------------------\n",
            "SVC()\n",
            "[[3329   56   20    7]\n",
            " [  25 3222  107   58]\n",
            " [  64  383 2350  615]\n",
            " [   9   60   90 3253]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.98      0.97      3412\n",
            "           0       0.87      0.94      0.90      3412\n",
            "           1       0.92      0.69      0.79      3412\n",
            "           2       0.83      0.95      0.89      3412\n",
            "\n",
            "    accuracy                           0.89     13648\n",
            "   macro avg       0.89      0.89      0.89     13648\n",
            "weighted avg       0.89      0.89      0.89     13648\n",
            "\n",
            "F1_score:  0.887\n",
            "-------------------------------------------------------\n",
            "KNeighborsClassifier()\n",
            "[[3082  326    0    4]\n",
            " [ 182 3201    5   24]\n",
            " [ 374 2328  620   90]\n",
            " [  97 1643   26 1646]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.83      0.90      0.86      3412\n",
            "           0       0.43      0.94      0.59      3412\n",
            "           1       0.95      0.18      0.31      3412\n",
            "           2       0.93      0.48      0.64      3412\n",
            "\n",
            "    accuracy                           0.63     13648\n",
            "   macro avg       0.78      0.63      0.60     13648\n",
            "weighted avg       0.78      0.63      0.60     13648\n",
            "\n",
            "F1_score:  0.598\n",
            "-------------------------------------------------------\n",
            "DecisionTreeClassifier()\n",
            "[[3366   28   16    2]\n",
            " [  51 3237   98   26]\n",
            " [ 230  511 2244  427]\n",
            " [  28  113  158 3113]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.92      0.99      0.95      3412\n",
            "           0       0.83      0.95      0.89      3412\n",
            "           1       0.89      0.66      0.76      3412\n",
            "           2       0.87      0.91      0.89      3412\n",
            "\n",
            "    accuracy                           0.88     13648\n",
            "   macro avg       0.88      0.88      0.87     13648\n",
            "weighted avg       0.88      0.88      0.87     13648\n",
            "\n",
            "F1_score:  0.871\n",
            "-------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6TV-1CHey4L"
      },
      "source": [
        "#Final Model Selected From Balanced Data Set"
      ],
      "id": "E6TV-1CHey4L"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQtxBCrue8Xf"
      },
      "source": [
        "Logistic Regression"
      ],
      "id": "eQtxBCrue8Xf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYOX61K1DxVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0630cd4-2f6a-46ba-d57b-cbf33c84a4a1"
      },
      "source": [
        "lr1=LogisticRegression() #multi_class{‘auto’, ‘ovr’, ‘multinomial’}, \n",
        "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
        "\n",
        "lr1.fit(count_train1, y_train1)\n",
        "lr_pred1 = lr1.predict(count_test1)\n",
        "metrics.accuracy_score(y_test1 ,lr_pred1)\n",
        "f1_score(y_test1, lr_pred1, average=\"macro\")"
      ],
      "id": "WYOX61K1DxVs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8910517537454319"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT6UCF59BWXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b6b325-5617-4db0-9a2d-e70b975709dc"
      },
      "source": [
        "f1_score(y_test1, lr_pred1, average=\"macro\")"
      ],
      "id": "xT6UCF59BWXE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8910517537454319"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-FeWsNGAMDC"
      },
      "source": [
        "SVC"
      ],
      "id": "D-FeWsNGAMDC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9tMZDw2ALJx",
        "outputId": "7987cd33-894b-4a69-851e-1dc8fa1c4e42"
      },
      "source": [
        "#svc = SVC(kernel='linear', gamma='auto', coef0=0.0000001, tol=0.0000002)   #,random_state=78)#{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
        "svc1= SVC(kernel='linear', C=10.0, random_state=1)\n",
        "svc1.fit(count_train1, y_train1)\n",
        "sv_pred1 = svc1.predict(count_test1)\n",
        "print(metrics.accuracy_score(y_test1 ,sv_pred1))\n",
        "print(f1_score(y_test1, sv_pred1, average=\"macro\"))"
      ],
      "id": "o9tMZDw2ALJx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8746069182389937\n",
            "0.8786387495645687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RJ4rz_HNw8w"
      },
      "source": [
        "RF"
      ],
      "id": "3RJ4rz_HNw8w"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdIIqy31NveW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608c846b-90d3-489d-926f-34a8515d8513"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc1 = RandomForestClassifier()\n",
        "rfc1.fit(count_train1, y_train1)\n",
        "rfc_pred1 = rfc1.predict(count_test1)\n",
        "print(metrics.accuracy_score(y_test1 ,rfc_pred1))\n",
        "print(f1_score(y_test1, rfc_pred1, average=\"macro\"))"
      ],
      "id": "PdIIqy31NveW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8759827044025157\n",
            "0.8809954765512442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m4uewY2kE4E"
      },
      "source": [
        "### The Chosen Model Summary⏰"
      ],
      "id": "4m4uewY2kE4E"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaRkmS-SkFBJ"
      },
      "source": [
        ""
      ],
      "id": "gaRkmS-SkFBJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT5hXiFNkKp2"
      },
      "source": [
        ""
      ],
      "id": "jT5hXiFNkKp2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QR2mnfgF-nJ"
      },
      "source": [
        "### Submission"
      ],
      "id": "8QR2mnfgF-nJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ddc2688"
      },
      "source": [
        "#pred = svc.predict(count_df_test)\n",
        "pred = lr1.predict(count_df_test1)"
      ],
      "id": "1ddc2688",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acfdf860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "82952350-6b16-44fe-cfee-01496f766c80"
      },
      "source": [
        "sub = pd.DataFrame({\"tweetid\":df_test['tweetid'], 'sentiment': pred})\n",
        "sub = sub.set_index('tweetid')\n",
        "sub.to_csv('submission.csv',index=True)\n",
        "sub.head()"
      ],
      "id": "acfdf860",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweetid</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169760</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35326</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224985</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476263</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872928</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "tweetid           \n",
              "169760           1\n",
              "35326            0\n",
              "224985           1\n",
              "476263           1\n",
              "872928           0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}